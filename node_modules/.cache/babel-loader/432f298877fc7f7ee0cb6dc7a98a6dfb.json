{"ast":null,"code":"/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport * as arrays from '../../../base/common/arrays.js';\nimport { LineTokens } from '../core/lineTokens.js';\nimport { Position } from '../core/position.js';\nimport { Range } from '../core/range.js';\nimport { TokenMetadata } from '../modes.js';\nexport function countEOL(text) {\n  let eolCount = 0;\n  let firstLineLength = 0;\n  let lastLineStart = 0;\n  let eol = 0\n  /* Unknown */\n  ;\n\n  for (let i = 0, len = text.length; i < len; i++) {\n    const chr = text.charCodeAt(i);\n\n    if (chr === 13\n    /* CarriageReturn */\n    ) {\n      if (eolCount === 0) {\n        firstLineLength = i;\n      }\n\n      eolCount++;\n\n      if (i + 1 < len && text.charCodeAt(i + 1) === 10\n      /* LineFeed */\n      ) {\n        // \\r\\n... case\n        eol |= 2\n        /* CRLF */\n        ;\n        i++; // skip \\n\n      } else {\n        // \\r... case\n        eol |= 3\n        /* Invalid */\n        ;\n      }\n\n      lastLineStart = i + 1;\n    } else if (chr === 10\n    /* LineFeed */\n    ) {\n      // \\n... case\n      eol |= 1\n      /* LF */\n      ;\n\n      if (eolCount === 0) {\n        firstLineLength = i;\n      }\n\n      eolCount++;\n      lastLineStart = i + 1;\n    }\n  }\n\n  if (eolCount === 0) {\n    firstLineLength = text.length;\n  }\n\n  return [eolCount, firstLineLength, text.length - lastLineStart, eol];\n}\n\nfunction getDefaultMetadata(topLevelLanguageId) {\n  return (topLevelLanguageId << 0\n  /* LANGUAGEID_OFFSET */\n  | 0\n  /* Other */\n  << 8\n  /* TOKEN_TYPE_OFFSET */\n  | 0\n  /* None */\n  << 11\n  /* FONT_STYLE_OFFSET */\n  | 1\n  /* DefaultForeground */\n  << 14\n  /* FOREGROUND_OFFSET */\n  | 2\n  /* DefaultBackground */\n  << 23\n  /* BACKGROUND_OFFSET */\n  ) >>> 0;\n}\n\nconst EMPTY_LINE_TOKENS = new Uint32Array(0).buffer;\nexport class MultilineTokensBuilder {\n  constructor() {\n    this.tokens = [];\n  }\n\n  add(lineNumber, lineTokens) {\n    if (this.tokens.length > 0) {\n      const last = this.tokens[this.tokens.length - 1];\n      const lastLineNumber = last.startLineNumber + last.tokens.length - 1;\n\n      if (lastLineNumber + 1 === lineNumber) {\n        // append\n        last.tokens.push(lineTokens);\n        return;\n      }\n    }\n\n    this.tokens.push(new MultilineTokens(lineNumber, [lineTokens]));\n  }\n\n}\nexport class SparseEncodedTokens {\n  constructor(tokens) {\n    this._tokens = tokens;\n    this._tokenCount = tokens.length / 4;\n  }\n\n  toString(startLineNumber) {\n    let pieces = [];\n\n    for (let i = 0; i < this._tokenCount; i++) {\n      pieces.push(`(${this._getDeltaLine(i) + startLineNumber},${this._getStartCharacter(i)}-${this._getEndCharacter(i)})`);\n    }\n\n    return `[${pieces.join(',')}]`;\n  }\n\n  getMaxDeltaLine() {\n    const tokenCount = this._getTokenCount();\n\n    if (tokenCount === 0) {\n      return -1;\n    }\n\n    return this._getDeltaLine(tokenCount - 1);\n  }\n\n  getRange() {\n    const tokenCount = this._getTokenCount();\n\n    if (tokenCount === 0) {\n      return null;\n    }\n\n    const startChar = this._getStartCharacter(0);\n\n    const maxDeltaLine = this._getDeltaLine(tokenCount - 1);\n\n    const endChar = this._getEndCharacter(tokenCount - 1);\n\n    return new Range(0, startChar + 1, maxDeltaLine, endChar + 1);\n  }\n\n  _getTokenCount() {\n    return this._tokenCount;\n  }\n\n  _getDeltaLine(tokenIndex) {\n    return this._tokens[4 * tokenIndex];\n  }\n\n  _getStartCharacter(tokenIndex) {\n    return this._tokens[4 * tokenIndex + 1];\n  }\n\n  _getEndCharacter(tokenIndex) {\n    return this._tokens[4 * tokenIndex + 2];\n  }\n\n  isEmpty() {\n    return this._getTokenCount() === 0;\n  }\n\n  getLineTokens(deltaLine) {\n    let low = 0;\n    let high = this._getTokenCount() - 1;\n\n    while (low < high) {\n      const mid = low + Math.floor((high - low) / 2);\n\n      const midDeltaLine = this._getDeltaLine(mid);\n\n      if (midDeltaLine < deltaLine) {\n        low = mid + 1;\n      } else if (midDeltaLine > deltaLine) {\n        high = mid - 1;\n      } else {\n        let min = mid;\n\n        while (min > low && this._getDeltaLine(min - 1) === deltaLine) {\n          min--;\n        }\n\n        let max = mid;\n\n        while (max < high && this._getDeltaLine(max + 1) === deltaLine) {\n          max++;\n        }\n\n        return new LineTokens2(this._tokens.subarray(4 * min, 4 * max + 4));\n      }\n    }\n\n    if (this._getDeltaLine(low) === deltaLine) {\n      return new LineTokens2(this._tokens.subarray(4 * low, 4 * low + 4));\n    }\n\n    return null;\n  }\n\n  clear() {\n    this._tokenCount = 0;\n  }\n\n  removeTokens(startDeltaLine, startChar, endDeltaLine, endChar) {\n    const tokens = this._tokens;\n    const tokenCount = this._tokenCount;\n    let newTokenCount = 0;\n    let hasDeletedTokens = false;\n    let firstDeltaLine = 0;\n\n    for (let i = 0; i < tokenCount; i++) {\n      const srcOffset = 4 * i;\n      const tokenDeltaLine = tokens[srcOffset];\n      const tokenStartCharacter = tokens[srcOffset + 1];\n      const tokenEndCharacter = tokens[srcOffset + 2];\n      const tokenMetadata = tokens[srcOffset + 3];\n\n      if ((tokenDeltaLine > startDeltaLine || tokenDeltaLine === startDeltaLine && tokenEndCharacter >= startChar) && (tokenDeltaLine < endDeltaLine || tokenDeltaLine === endDeltaLine && tokenStartCharacter <= endChar)) {\n        hasDeletedTokens = true;\n      } else {\n        if (newTokenCount === 0) {\n          firstDeltaLine = tokenDeltaLine;\n        }\n\n        if (hasDeletedTokens) {\n          // must move the token to the left\n          const destOffset = 4 * newTokenCount;\n          tokens[destOffset] = tokenDeltaLine - firstDeltaLine;\n          tokens[destOffset + 1] = tokenStartCharacter;\n          tokens[destOffset + 2] = tokenEndCharacter;\n          tokens[destOffset + 3] = tokenMetadata;\n        }\n\n        newTokenCount++;\n      }\n    }\n\n    this._tokenCount = newTokenCount;\n    return firstDeltaLine;\n  }\n\n  split(startDeltaLine, startChar, endDeltaLine, endChar) {\n    const tokens = this._tokens;\n    const tokenCount = this._tokenCount;\n    let aTokens = [];\n    let bTokens = [];\n    let destTokens = aTokens;\n    let destOffset = 0;\n    let destFirstDeltaLine = 0;\n\n    for (let i = 0; i < tokenCount; i++) {\n      const srcOffset = 4 * i;\n      const tokenDeltaLine = tokens[srcOffset];\n      const tokenStartCharacter = tokens[srcOffset + 1];\n      const tokenEndCharacter = tokens[srcOffset + 2];\n      const tokenMetadata = tokens[srcOffset + 3];\n\n      if (tokenDeltaLine > startDeltaLine || tokenDeltaLine === startDeltaLine && tokenEndCharacter >= startChar) {\n        if (tokenDeltaLine < endDeltaLine || tokenDeltaLine === endDeltaLine && tokenStartCharacter <= endChar) {\n          // this token is touching the range\n          continue;\n        } else {\n          // this token is after the range\n          if (destTokens !== bTokens) {\n            // this token is the first token after the range\n            destTokens = bTokens;\n            destOffset = 0;\n            destFirstDeltaLine = tokenDeltaLine;\n          }\n        }\n      }\n\n      destTokens[destOffset++] = tokenDeltaLine - destFirstDeltaLine;\n      destTokens[destOffset++] = tokenStartCharacter;\n      destTokens[destOffset++] = tokenEndCharacter;\n      destTokens[destOffset++] = tokenMetadata;\n    }\n\n    return [new SparseEncodedTokens(new Uint32Array(aTokens)), new SparseEncodedTokens(new Uint32Array(bTokens)), destFirstDeltaLine];\n  }\n\n  acceptDeleteRange(horizontalShiftForFirstLineTokens, startDeltaLine, startCharacter, endDeltaLine, endCharacter) {\n    // This is a bit complex, here are the cases I used to think about this:\n    //\n    // 1. The token starts before the deletion range\n    // 1a. The token is completely before the deletion range\n    //               -----------\n    //                          xxxxxxxxxxx\n    // 1b. The token starts before, the deletion range ends after the token\n    //               -----------\n    //                      xxxxxxxxxxx\n    // 1c. The token starts before, the deletion range ends precisely with the token\n    //               ---------------\n    //                      xxxxxxxx\n    // 1d. The token starts before, the deletion range is inside the token\n    //               ---------------\n    //                    xxxxx\n    //\n    // 2. The token starts at the same position with the deletion range\n    // 2a. The token starts at the same position, and ends inside the deletion range\n    //               -------\n    //               xxxxxxxxxxx\n    // 2b. The token starts at the same position, and ends at the same position as the deletion range\n    //               ----------\n    //               xxxxxxxxxx\n    // 2c. The token starts at the same position, and ends after the deletion range\n    //               -------------\n    //               xxxxxxx\n    //\n    // 3. The token starts inside the deletion range\n    // 3a. The token is inside the deletion range\n    //                -------\n    //             xxxxxxxxxxxxx\n    // 3b. The token starts inside the deletion range, and ends at the same position as the deletion range\n    //                ----------\n    //             xxxxxxxxxxxxx\n    // 3c. The token starts inside the deletion range, and ends after the deletion range\n    //                ------------\n    //             xxxxxxxxxxx\n    //\n    // 4. The token starts after the deletion range\n    //                  -----------\n    //          xxxxxxxx\n    //\n    const tokens = this._tokens;\n    const tokenCount = this._tokenCount;\n    const deletedLineCount = endDeltaLine - startDeltaLine;\n    let newTokenCount = 0;\n    let hasDeletedTokens = false;\n\n    for (let i = 0; i < tokenCount; i++) {\n      const srcOffset = 4 * i;\n      let tokenDeltaLine = tokens[srcOffset];\n      let tokenStartCharacter = tokens[srcOffset + 1];\n      let tokenEndCharacter = tokens[srcOffset + 2];\n      const tokenMetadata = tokens[srcOffset + 3];\n\n      if (tokenDeltaLine < startDeltaLine || tokenDeltaLine === startDeltaLine && tokenEndCharacter <= startCharacter) {\n        // 1a. The token is completely before the deletion range\n        // => nothing to do\n        newTokenCount++;\n        continue;\n      } else if (tokenDeltaLine === startDeltaLine && tokenStartCharacter < startCharacter) {\n        // 1b, 1c, 1d\n        // => the token survives, but it needs to shrink\n        if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n          // 1d. The token starts before, the deletion range is inside the token\n          // => the token shrinks by the deletion character count\n          tokenEndCharacter -= endCharacter - startCharacter;\n        } else {\n          // 1b. The token starts before, the deletion range ends after the token\n          // 1c. The token starts before, the deletion range ends precisely with the token\n          // => the token shrinks its ending to the deletion start\n          tokenEndCharacter = startCharacter;\n        }\n      } else if (tokenDeltaLine === startDeltaLine && tokenStartCharacter === startCharacter) {\n        // 2a, 2b, 2c\n        if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n          // 2c. The token starts at the same position, and ends after the deletion range\n          // => the token shrinks by the deletion character count\n          tokenEndCharacter -= endCharacter - startCharacter;\n        } else {\n          // 2a. The token starts at the same position, and ends inside the deletion range\n          // 2b. The token starts at the same position, and ends at the same position as the deletion range\n          // => the token is deleted\n          hasDeletedTokens = true;\n          continue;\n        }\n      } else if (tokenDeltaLine < endDeltaLine || tokenDeltaLine === endDeltaLine && tokenStartCharacter < endCharacter) {\n        // 3a, 3b, 3c\n        if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n          // 3c. The token starts inside the deletion range, and ends after the deletion range\n          // => the token moves left and shrinks\n          if (tokenDeltaLine === startDeltaLine) {\n            // the deletion started on the same line as the token\n            // => the token moves left and shrinks\n            tokenStartCharacter = startCharacter;\n            tokenEndCharacter = tokenStartCharacter + (tokenEndCharacter - endCharacter);\n          } else {\n            // the deletion started on a line above the token\n            // => the token moves to the beginning of the line\n            tokenStartCharacter = 0;\n            tokenEndCharacter = tokenStartCharacter + (tokenEndCharacter - endCharacter);\n          }\n        } else {\n          // 3a. The token is inside the deletion range\n          // 3b. The token starts inside the deletion range, and ends at the same position as the deletion range\n          // => the token is deleted\n          hasDeletedTokens = true;\n          continue;\n        }\n      } else if (tokenDeltaLine > endDeltaLine) {\n        // 4. (partial) The token starts after the deletion range, on a line below...\n        if (deletedLineCount === 0 && !hasDeletedTokens) {\n          // early stop, there is no need to walk all the tokens and do nothing...\n          newTokenCount = tokenCount;\n          break;\n        }\n\n        tokenDeltaLine -= deletedLineCount;\n      } else if (tokenDeltaLine === endDeltaLine && tokenStartCharacter >= endCharacter) {\n        // 4. (continued) The token starts after the deletion range, on the last line where a deletion occurs\n        if (horizontalShiftForFirstLineTokens && tokenDeltaLine === 0) {\n          tokenStartCharacter += horizontalShiftForFirstLineTokens;\n          tokenEndCharacter += horizontalShiftForFirstLineTokens;\n        }\n\n        tokenDeltaLine -= deletedLineCount;\n        tokenStartCharacter -= endCharacter - startCharacter;\n        tokenEndCharacter -= endCharacter - startCharacter;\n      } else {\n        throw new Error(`Not possible!`);\n      }\n\n      const destOffset = 4 * newTokenCount;\n      tokens[destOffset] = tokenDeltaLine;\n      tokens[destOffset + 1] = tokenStartCharacter;\n      tokens[destOffset + 2] = tokenEndCharacter;\n      tokens[destOffset + 3] = tokenMetadata;\n      newTokenCount++;\n    }\n\n    this._tokenCount = newTokenCount;\n  }\n\n  acceptInsertText(deltaLine, character, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n    // Here are the cases I used to think about this:\n    //\n    // 1. The token is completely before the insertion point\n    //            -----------   |\n    // 2. The token ends precisely at the insertion point\n    //            -----------|\n    // 3. The token contains the insertion point\n    //            -----|------\n    // 4. The token starts precisely at the insertion point\n    //            |-----------\n    // 5. The token is completely after the insertion point\n    //            |   -----------\n    //\n    const isInsertingPreciselyOneWordCharacter = eolCount === 0 && firstLineLength === 1 && (firstCharCode >= 48\n    /* Digit0 */\n    && firstCharCode <= 57\n    /* Digit9 */\n    || firstCharCode >= 65\n    /* A */\n    && firstCharCode <= 90\n    /* Z */\n    || firstCharCode >= 97\n    /* a */\n    && firstCharCode <= 122\n    /* z */\n    );\n    const tokens = this._tokens;\n    const tokenCount = this._tokenCount;\n\n    for (let i = 0; i < tokenCount; i++) {\n      const offset = 4 * i;\n      let tokenDeltaLine = tokens[offset];\n      let tokenStartCharacter = tokens[offset + 1];\n      let tokenEndCharacter = tokens[offset + 2];\n\n      if (tokenDeltaLine < deltaLine || tokenDeltaLine === deltaLine && tokenEndCharacter < character) {\n        // 1. The token is completely before the insertion point\n        // => nothing to do\n        continue;\n      } else if (tokenDeltaLine === deltaLine && tokenEndCharacter === character) {\n        // 2. The token ends precisely at the insertion point\n        // => expand the end character only if inserting precisely one character that is a word character\n        if (isInsertingPreciselyOneWordCharacter) {\n          tokenEndCharacter += 1;\n        } else {\n          continue;\n        }\n      } else if (tokenDeltaLine === deltaLine && tokenStartCharacter < character && character < tokenEndCharacter) {\n        // 3. The token contains the insertion point\n        if (eolCount === 0) {\n          // => just expand the end character\n          tokenEndCharacter += firstLineLength;\n        } else {\n          // => cut off the token\n          tokenEndCharacter = character;\n        }\n      } else {\n        // 4. or 5.\n        if (tokenDeltaLine === deltaLine && tokenStartCharacter === character) {\n          // 4. The token starts precisely at the insertion point\n          // => grow the token (by keeping its start constant) only if inserting precisely one character that is a word character\n          // => otherwise behave as in case 5.\n          if (isInsertingPreciselyOneWordCharacter) {\n            continue;\n          }\n        } // => the token must move and keep its size constant\n\n\n        if (tokenDeltaLine === deltaLine) {\n          tokenDeltaLine += eolCount; // this token is on the line where the insertion is taking place\n\n          if (eolCount === 0) {\n            tokenStartCharacter += firstLineLength;\n            tokenEndCharacter += firstLineLength;\n          } else {\n            const tokenLength = tokenEndCharacter - tokenStartCharacter;\n            tokenStartCharacter = lastLineLength + (tokenStartCharacter - character);\n            tokenEndCharacter = tokenStartCharacter + tokenLength;\n          }\n        } else {\n          tokenDeltaLine += eolCount;\n        }\n      }\n\n      tokens[offset] = tokenDeltaLine;\n      tokens[offset + 1] = tokenStartCharacter;\n      tokens[offset + 2] = tokenEndCharacter;\n    }\n  }\n\n}\nexport class LineTokens2 {\n  constructor(tokens) {\n    this._tokens = tokens;\n  }\n\n  getCount() {\n    return this._tokens.length / 4;\n  }\n\n  getStartCharacter(tokenIndex) {\n    return this._tokens[4 * tokenIndex + 1];\n  }\n\n  getEndCharacter(tokenIndex) {\n    return this._tokens[4 * tokenIndex + 2];\n  }\n\n  getMetadata(tokenIndex) {\n    return this._tokens[4 * tokenIndex + 3];\n  }\n\n}\nexport class MultilineTokens2 {\n  constructor(startLineNumber, tokens) {\n    this.startLineNumber = startLineNumber;\n    this.tokens = tokens;\n    this.endLineNumber = this.startLineNumber + this.tokens.getMaxDeltaLine();\n  }\n\n  toString() {\n    return this.tokens.toString(this.startLineNumber);\n  }\n\n  _updateEndLineNumber() {\n    this.endLineNumber = this.startLineNumber + this.tokens.getMaxDeltaLine();\n  }\n\n  isEmpty() {\n    return this.tokens.isEmpty();\n  }\n\n  getLineTokens(lineNumber) {\n    if (this.startLineNumber <= lineNumber && lineNumber <= this.endLineNumber) {\n      return this.tokens.getLineTokens(lineNumber - this.startLineNumber);\n    }\n\n    return null;\n  }\n\n  getRange() {\n    const deltaRange = this.tokens.getRange();\n\n    if (!deltaRange) {\n      return deltaRange;\n    }\n\n    return new Range(this.startLineNumber + deltaRange.startLineNumber, deltaRange.startColumn, this.startLineNumber + deltaRange.endLineNumber, deltaRange.endColumn);\n  }\n\n  removeTokens(range) {\n    const startLineIndex = range.startLineNumber - this.startLineNumber;\n    const endLineIndex = range.endLineNumber - this.startLineNumber;\n    this.startLineNumber += this.tokens.removeTokens(startLineIndex, range.startColumn - 1, endLineIndex, range.endColumn - 1);\n\n    this._updateEndLineNumber();\n  }\n\n  split(range) {\n    // split tokens to two:\n    // a) all the tokens before `range`\n    // b) all the tokens after `range`\n    const startLineIndex = range.startLineNumber - this.startLineNumber;\n    const endLineIndex = range.endLineNumber - this.startLineNumber;\n    const [a, b, bDeltaLine] = this.tokens.split(startLineIndex, range.startColumn - 1, endLineIndex, range.endColumn - 1);\n    return [new MultilineTokens2(this.startLineNumber, a), new MultilineTokens2(this.startLineNumber + bDeltaLine, b)];\n  }\n\n  applyEdit(range, text) {\n    const [eolCount, firstLineLength, lastLineLength] = countEOL(text);\n    this.acceptEdit(range, eolCount, firstLineLength, lastLineLength, text.length > 0 ? text.charCodeAt(0) : 0\n    /* Null */\n    );\n  }\n\n  acceptEdit(range, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n    this._acceptDeleteRange(range);\n\n    this._acceptInsertText(new Position(range.startLineNumber, range.startColumn), eolCount, firstLineLength, lastLineLength, firstCharCode);\n\n    this._updateEndLineNumber();\n  }\n\n  _acceptDeleteRange(range) {\n    if (range.startLineNumber === range.endLineNumber && range.startColumn === range.endColumn) {\n      // Nothing to delete\n      return;\n    }\n\n    const firstLineIndex = range.startLineNumber - this.startLineNumber;\n    const lastLineIndex = range.endLineNumber - this.startLineNumber;\n\n    if (lastLineIndex < 0) {\n      // this deletion occurs entirely before this block, so we only need to adjust line numbers\n      const deletedLinesCount = lastLineIndex - firstLineIndex;\n      this.startLineNumber -= deletedLinesCount;\n      return;\n    }\n\n    const tokenMaxDeltaLine = this.tokens.getMaxDeltaLine();\n\n    if (firstLineIndex >= tokenMaxDeltaLine + 1) {\n      // this deletion occurs entirely after this block, so there is nothing to do\n      return;\n    }\n\n    if (firstLineIndex < 0 && lastLineIndex >= tokenMaxDeltaLine + 1) {\n      // this deletion completely encompasses this block\n      this.startLineNumber = 0;\n      this.tokens.clear();\n      return;\n    }\n\n    if (firstLineIndex < 0) {\n      const deletedBefore = -firstLineIndex;\n      this.startLineNumber -= deletedBefore;\n      this.tokens.acceptDeleteRange(range.startColumn - 1, 0, 0, lastLineIndex, range.endColumn - 1);\n    } else {\n      this.tokens.acceptDeleteRange(0, firstLineIndex, range.startColumn - 1, lastLineIndex, range.endColumn - 1);\n    }\n  }\n\n  _acceptInsertText(position, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n    if (eolCount === 0 && firstLineLength === 0) {\n      // Nothing to insert\n      return;\n    }\n\n    const lineIndex = position.lineNumber - this.startLineNumber;\n\n    if (lineIndex < 0) {\n      // this insertion occurs before this block, so we only need to adjust line numbers\n      this.startLineNumber += eolCount;\n      return;\n    }\n\n    const tokenMaxDeltaLine = this.tokens.getMaxDeltaLine();\n\n    if (lineIndex >= tokenMaxDeltaLine + 1) {\n      // this insertion occurs after this block, so there is nothing to do\n      return;\n    }\n\n    this.tokens.acceptInsertText(lineIndex, position.column - 1, eolCount, firstLineLength, lastLineLength, firstCharCode);\n  }\n\n}\nexport class MultilineTokens {\n  constructor(startLineNumber, tokens) {\n    this.startLineNumber = startLineNumber;\n    this.tokens = tokens;\n  }\n\n}\n\nfunction toUint32Array(arr) {\n  if (arr instanceof Uint32Array) {\n    return arr;\n  } else {\n    return new Uint32Array(arr);\n  }\n}\n\nexport class TokensStore2 {\n  constructor(languageIdCodec) {\n    this._pieces = [];\n    this._isComplete = false;\n    this._languageIdCodec = languageIdCodec;\n  }\n\n  flush() {\n    this._pieces = [];\n    this._isComplete = false;\n  }\n\n  isEmpty() {\n    return this._pieces.length === 0;\n  }\n\n  set(pieces, isComplete) {\n    this._pieces = pieces || [];\n    this._isComplete = isComplete;\n  }\n\n  setPartial(_range, pieces) {\n    // console.log(`setPartial ${_range} ${pieces.map(p => p.toString()).join(', ')}`);\n    let range = _range;\n\n    if (pieces.length > 0) {\n      const _firstRange = pieces[0].getRange();\n\n      const _lastRange = pieces[pieces.length - 1].getRange();\n\n      if (!_firstRange || !_lastRange) {\n        return _range;\n      }\n\n      range = _range.plusRange(_firstRange).plusRange(_lastRange);\n    }\n\n    let insertPosition = null;\n\n    for (let i = 0, len = this._pieces.length; i < len; i++) {\n      const piece = this._pieces[i];\n\n      if (piece.endLineNumber < range.startLineNumber) {\n        // this piece is before the range\n        continue;\n      }\n\n      if (piece.startLineNumber > range.endLineNumber) {\n        // this piece is after the range, so mark the spot before this piece\n        // as a good insertion position and stop looping\n        insertPosition = insertPosition || {\n          index: i\n        };\n        break;\n      } // this piece might intersect with the range\n\n\n      piece.removeTokens(range);\n\n      if (piece.isEmpty()) {\n        // remove the piece if it became empty\n        this._pieces.splice(i, 1);\n\n        i--;\n        len--;\n        continue;\n      }\n\n      if (piece.endLineNumber < range.startLineNumber) {\n        // after removal, this piece is before the range\n        continue;\n      }\n\n      if (piece.startLineNumber > range.endLineNumber) {\n        // after removal, this piece is after the range\n        insertPosition = insertPosition || {\n          index: i\n        };\n        continue;\n      } // after removal, this piece contains the range\n\n\n      const [a, b] = piece.split(range);\n\n      if (a.isEmpty()) {\n        // this piece is actually after the range\n        insertPosition = insertPosition || {\n          index: i\n        };\n        continue;\n      }\n\n      if (b.isEmpty()) {\n        // this piece is actually before the range\n        continue;\n      }\n\n      this._pieces.splice(i, 1, a, b);\n\n      i++;\n      len++;\n      insertPosition = insertPosition || {\n        index: i\n      };\n    }\n\n    insertPosition = insertPosition || {\n      index: this._pieces.length\n    };\n\n    if (pieces.length > 0) {\n      this._pieces = arrays.arrayInsert(this._pieces, insertPosition.index, pieces);\n    } // console.log(`I HAVE ${this._pieces.length} pieces`);\n    // console.log(`${this._pieces.map(p => p.toString()).join('\\n')}`);\n\n\n    return range;\n  }\n\n  isComplete() {\n    return this._isComplete;\n  }\n\n  addSemanticTokens(lineNumber, aTokens) {\n    const pieces = this._pieces;\n\n    if (pieces.length === 0) {\n      return aTokens;\n    }\n\n    const pieceIndex = TokensStore2._findFirstPieceWithLine(pieces, lineNumber);\n\n    const bTokens = pieces[pieceIndex].getLineTokens(lineNumber);\n\n    if (!bTokens) {\n      return aTokens;\n    }\n\n    const aLen = aTokens.getCount();\n    const bLen = bTokens.getCount();\n    let aIndex = 0;\n    let result = [],\n        resultLen = 0;\n    let lastEndOffset = 0;\n\n    const emitToken = (endOffset, metadata) => {\n      if (endOffset === lastEndOffset) {\n        return;\n      }\n\n      lastEndOffset = endOffset;\n      result[resultLen++] = endOffset;\n      result[resultLen++] = metadata;\n    };\n\n    for (let bIndex = 0; bIndex < bLen; bIndex++) {\n      const bStartCharacter = bTokens.getStartCharacter(bIndex);\n      const bEndCharacter = bTokens.getEndCharacter(bIndex);\n      const bMetadata = bTokens.getMetadata(bIndex);\n      const bMask = ((bMetadata & 1\n      /* SEMANTIC_USE_ITALIC */\n      ? 2048\n      /* ITALIC_MASK */\n      : 0) | (bMetadata & 2\n      /* SEMANTIC_USE_BOLD */\n      ? 4096\n      /* BOLD_MASK */\n      : 0) | (bMetadata & 4\n      /* SEMANTIC_USE_UNDERLINE */\n      ? 8192\n      /* UNDERLINE_MASK */\n      : 0) | (bMetadata & 8\n      /* SEMANTIC_USE_FOREGROUND */\n      ? 8372224\n      /* FOREGROUND_MASK */\n      : 0) | (bMetadata & 16\n      /* SEMANTIC_USE_BACKGROUND */\n      ? 4286578688\n      /* BACKGROUND_MASK */\n      : 0)) >>> 0;\n      const aMask = ~bMask >>> 0; // push any token from `a` that is before `b`\n\n      while (aIndex < aLen && aTokens.getEndOffset(aIndex) <= bStartCharacter) {\n        emitToken(aTokens.getEndOffset(aIndex), aTokens.getMetadata(aIndex));\n        aIndex++;\n      } // push the token from `a` if it intersects the token from `b`\n\n\n      if (aIndex < aLen && aTokens.getStartOffset(aIndex) < bStartCharacter) {\n        emitToken(bStartCharacter, aTokens.getMetadata(aIndex));\n      } // skip any tokens from `a` that are contained inside `b`\n\n\n      while (aIndex < aLen && aTokens.getEndOffset(aIndex) < bEndCharacter) {\n        emitToken(aTokens.getEndOffset(aIndex), aTokens.getMetadata(aIndex) & aMask | bMetadata & bMask);\n        aIndex++;\n      }\n\n      if (aIndex < aLen) {\n        emitToken(bEndCharacter, aTokens.getMetadata(aIndex) & aMask | bMetadata & bMask);\n\n        if (aTokens.getEndOffset(aIndex) === bEndCharacter) {\n          // `a` ends exactly at the same spot as `b`!\n          aIndex++;\n        }\n      } else {\n        const aMergeIndex = Math.min(Math.max(0, aIndex - 1), aLen - 1); // push the token from `b`\n\n        emitToken(bEndCharacter, aTokens.getMetadata(aMergeIndex) & aMask | bMetadata & bMask);\n      }\n    } // push the remaining tokens from `a`\n\n\n    while (aIndex < aLen) {\n      emitToken(aTokens.getEndOffset(aIndex), aTokens.getMetadata(aIndex));\n      aIndex++;\n    }\n\n    return new LineTokens(new Uint32Array(result), aTokens.getLineContent(), this._languageIdCodec);\n  }\n\n  static _findFirstPieceWithLine(pieces, lineNumber) {\n    let low = 0;\n    let high = pieces.length - 1;\n\n    while (low < high) {\n      let mid = low + Math.floor((high - low) / 2);\n\n      if (pieces[mid].endLineNumber < lineNumber) {\n        low = mid + 1;\n      } else if (pieces[mid].startLineNumber > lineNumber) {\n        high = mid - 1;\n      } else {\n        while (mid > low && pieces[mid - 1].startLineNumber <= lineNumber && lineNumber <= pieces[mid - 1].endLineNumber) {\n          mid--;\n        }\n\n        return mid;\n      }\n    }\n\n    return low;\n  } //#region Editing\n\n\n  acceptEdit(range, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n    for (const piece of this._pieces) {\n      piece.acceptEdit(range, eolCount, firstLineLength, lastLineLength, firstCharCode);\n    }\n  }\n\n}\nexport class TokensStore {\n  constructor(languageIdCodec) {\n    this._lineTokens = [];\n    this._len = 0;\n    this._languageIdCodec = languageIdCodec;\n  }\n\n  flush() {\n    this._lineTokens = [];\n    this._len = 0;\n  }\n\n  getTokens(topLevelLanguageId, lineIndex, lineText) {\n    let rawLineTokens = null;\n\n    if (lineIndex < this._len) {\n      rawLineTokens = this._lineTokens[lineIndex];\n    }\n\n    if (rawLineTokens !== null && rawLineTokens !== EMPTY_LINE_TOKENS) {\n      return new LineTokens(toUint32Array(rawLineTokens), lineText, this._languageIdCodec);\n    }\n\n    const lineTokens = new Uint32Array(2);\n    lineTokens[0] = lineText.length;\n    lineTokens[1] = getDefaultMetadata(this._languageIdCodec.encodeLanguageId(topLevelLanguageId));\n    return new LineTokens(lineTokens, lineText, this._languageIdCodec);\n  }\n\n  static _massageTokens(topLevelLanguageId, lineTextLength, _tokens) {\n    const tokens = _tokens ? toUint32Array(_tokens) : null;\n\n    if (lineTextLength === 0) {\n      let hasDifferentLanguageId = false;\n\n      if (tokens && tokens.length > 1) {\n        hasDifferentLanguageId = TokenMetadata.getLanguageId(tokens[1]) !== topLevelLanguageId;\n      }\n\n      if (!hasDifferentLanguageId) {\n        return EMPTY_LINE_TOKENS;\n      }\n    }\n\n    if (!tokens || tokens.length === 0) {\n      const tokens = new Uint32Array(2);\n      tokens[0] = lineTextLength;\n      tokens[1] = getDefaultMetadata(topLevelLanguageId);\n      return tokens.buffer;\n    } // Ensure the last token covers the end of the text\n\n\n    tokens[tokens.length - 2] = lineTextLength;\n\n    if (tokens.byteOffset === 0 && tokens.byteLength === tokens.buffer.byteLength) {\n      // Store directly the ArrayBuffer pointer to save an object\n      return tokens.buffer;\n    }\n\n    return tokens;\n  }\n\n  _ensureLine(lineIndex) {\n    while (lineIndex >= this._len) {\n      this._lineTokens[this._len] = null;\n      this._len++;\n    }\n  }\n\n  _deleteLines(start, deleteCount) {\n    if (deleteCount === 0) {\n      return;\n    }\n\n    if (start + deleteCount > this._len) {\n      deleteCount = this._len - start;\n    }\n\n    this._lineTokens.splice(start, deleteCount);\n\n    this._len -= deleteCount;\n  }\n\n  _insertLines(insertIndex, insertCount) {\n    if (insertCount === 0) {\n      return;\n    }\n\n    let lineTokens = [];\n\n    for (let i = 0; i < insertCount; i++) {\n      lineTokens[i] = null;\n    }\n\n    this._lineTokens = arrays.arrayInsert(this._lineTokens, insertIndex, lineTokens);\n    this._len += insertCount;\n  }\n\n  setTokens(topLevelLanguageId, lineIndex, lineTextLength, _tokens, checkEquality) {\n    const tokens = TokensStore._massageTokens(this._languageIdCodec.encodeLanguageId(topLevelLanguageId), lineTextLength, _tokens);\n\n    this._ensureLine(lineIndex);\n\n    const oldTokens = this._lineTokens[lineIndex];\n    this._lineTokens[lineIndex] = tokens;\n\n    if (checkEquality) {\n      return !TokensStore._equals(oldTokens, tokens);\n    }\n\n    return false;\n  }\n\n  static _equals(_a, _b) {\n    if (!_a || !_b) {\n      return !_a && !_b;\n    }\n\n    const a = toUint32Array(_a);\n    const b = toUint32Array(_b);\n\n    if (a.length !== b.length) {\n      return false;\n    }\n\n    for (let i = 0, len = a.length; i < len; i++) {\n      if (a[i] !== b[i]) {\n        return false;\n      }\n    }\n\n    return true;\n  } //#region Editing\n\n\n  acceptEdit(range, eolCount, firstLineLength) {\n    this._acceptDeleteRange(range);\n\n    this._acceptInsertText(new Position(range.startLineNumber, range.startColumn), eolCount, firstLineLength);\n  }\n\n  _acceptDeleteRange(range) {\n    const firstLineIndex = range.startLineNumber - 1;\n\n    if (firstLineIndex >= this._len) {\n      return;\n    }\n\n    if (range.startLineNumber === range.endLineNumber) {\n      if (range.startColumn === range.endColumn) {\n        // Nothing to delete\n        return;\n      }\n\n      this._lineTokens[firstLineIndex] = TokensStore._delete(this._lineTokens[firstLineIndex], range.startColumn - 1, range.endColumn - 1);\n      return;\n    }\n\n    this._lineTokens[firstLineIndex] = TokensStore._deleteEnding(this._lineTokens[firstLineIndex], range.startColumn - 1);\n    const lastLineIndex = range.endLineNumber - 1;\n    let lastLineTokens = null;\n\n    if (lastLineIndex < this._len) {\n      lastLineTokens = TokensStore._deleteBeginning(this._lineTokens[lastLineIndex], range.endColumn - 1);\n    } // Take remaining text on last line and append it to remaining text on first line\n\n\n    this._lineTokens[firstLineIndex] = TokensStore._append(this._lineTokens[firstLineIndex], lastLineTokens); // Delete middle lines\n\n    this._deleteLines(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n  }\n\n  _acceptInsertText(position, eolCount, firstLineLength) {\n    if (eolCount === 0 && firstLineLength === 0) {\n      // Nothing to insert\n      return;\n    }\n\n    const lineIndex = position.lineNumber - 1;\n\n    if (lineIndex >= this._len) {\n      return;\n    }\n\n    if (eolCount === 0) {\n      // Inserting text on one line\n      this._lineTokens[lineIndex] = TokensStore._insert(this._lineTokens[lineIndex], position.column - 1, firstLineLength);\n      return;\n    }\n\n    this._lineTokens[lineIndex] = TokensStore._deleteEnding(this._lineTokens[lineIndex], position.column - 1);\n    this._lineTokens[lineIndex] = TokensStore._insert(this._lineTokens[lineIndex], position.column - 1, firstLineLength);\n\n    this._insertLines(position.lineNumber, eolCount);\n  }\n\n  static _deleteBeginning(lineTokens, toChIndex) {\n    if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS) {\n      return lineTokens;\n    }\n\n    return TokensStore._delete(lineTokens, 0, toChIndex);\n  }\n\n  static _deleteEnding(lineTokens, fromChIndex) {\n    if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS) {\n      return lineTokens;\n    }\n\n    const tokens = toUint32Array(lineTokens);\n    const lineTextLength = tokens[tokens.length - 2];\n    return TokensStore._delete(lineTokens, fromChIndex, lineTextLength);\n  }\n\n  static _delete(lineTokens, fromChIndex, toChIndex) {\n    if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS || fromChIndex === toChIndex) {\n      return lineTokens;\n    }\n\n    const tokens = toUint32Array(lineTokens);\n    const tokensCount = tokens.length >>> 1; // special case: deleting everything\n\n    if (fromChIndex === 0 && tokens[tokens.length - 2] === toChIndex) {\n      return EMPTY_LINE_TOKENS;\n    }\n\n    const fromTokenIndex = LineTokens.findIndexInTokensArray(tokens, fromChIndex);\n    const fromTokenStartOffset = fromTokenIndex > 0 ? tokens[fromTokenIndex - 1 << 1] : 0;\n    const fromTokenEndOffset = tokens[fromTokenIndex << 1];\n\n    if (toChIndex < fromTokenEndOffset) {\n      // the delete range is inside a single token\n      const delta = toChIndex - fromChIndex;\n\n      for (let i = fromTokenIndex; i < tokensCount; i++) {\n        tokens[i << 1] -= delta;\n      }\n\n      return lineTokens;\n    }\n\n    let dest;\n    let lastEnd;\n\n    if (fromTokenStartOffset !== fromChIndex) {\n      tokens[fromTokenIndex << 1] = fromChIndex;\n      dest = fromTokenIndex + 1 << 1;\n      lastEnd = fromChIndex;\n    } else {\n      dest = fromTokenIndex << 1;\n      lastEnd = fromTokenStartOffset;\n    }\n\n    const delta = toChIndex - fromChIndex;\n\n    for (let tokenIndex = fromTokenIndex + 1; tokenIndex < tokensCount; tokenIndex++) {\n      const tokenEndOffset = tokens[tokenIndex << 1] - delta;\n\n      if (tokenEndOffset > lastEnd) {\n        tokens[dest++] = tokenEndOffset;\n        tokens[dest++] = tokens[(tokenIndex << 1) + 1];\n        lastEnd = tokenEndOffset;\n      }\n    }\n\n    if (dest === tokens.length) {\n      // nothing to trim\n      return lineTokens;\n    }\n\n    let tmp = new Uint32Array(dest);\n    tmp.set(tokens.subarray(0, dest), 0);\n    return tmp.buffer;\n  }\n\n  static _append(lineTokens, _otherTokens) {\n    if (_otherTokens === EMPTY_LINE_TOKENS) {\n      return lineTokens;\n    }\n\n    if (lineTokens === EMPTY_LINE_TOKENS) {\n      return _otherTokens;\n    }\n\n    if (lineTokens === null) {\n      return lineTokens;\n    }\n\n    if (_otherTokens === null) {\n      // cannot determine combined line length...\n      return null;\n    }\n\n    const myTokens = toUint32Array(lineTokens);\n    const otherTokens = toUint32Array(_otherTokens);\n    const otherTokensCount = otherTokens.length >>> 1;\n    let result = new Uint32Array(myTokens.length + otherTokens.length);\n    result.set(myTokens, 0);\n    let dest = myTokens.length;\n    const delta = myTokens[myTokens.length - 2];\n\n    for (let i = 0; i < otherTokensCount; i++) {\n      result[dest++] = otherTokens[i << 1] + delta;\n      result[dest++] = otherTokens[(i << 1) + 1];\n    }\n\n    return result.buffer;\n  }\n\n  static _insert(lineTokens, chIndex, textLength) {\n    if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS) {\n      // nothing to do\n      return lineTokens;\n    }\n\n    const tokens = toUint32Array(lineTokens);\n    const tokensCount = tokens.length >>> 1;\n    let fromTokenIndex = LineTokens.findIndexInTokensArray(tokens, chIndex);\n\n    if (fromTokenIndex > 0) {\n      const fromTokenStartOffset = tokens[fromTokenIndex - 1 << 1];\n\n      if (fromTokenStartOffset === chIndex) {\n        fromTokenIndex--;\n      }\n    }\n\n    for (let tokenIndex = fromTokenIndex; tokenIndex < tokensCount; tokenIndex++) {\n      tokens[tokenIndex << 1] += textLength;\n    }\n\n    return lineTokens;\n  }\n\n}","map":{"version":3,"sources":["/home/umut/Documents/cs/cs410/Project2Group14/node_modules/monaco-editor/esm/vs/editor/common/model/tokensStore.js"],"names":["arrays","LineTokens","Position","Range","TokenMetadata","countEOL","text","eolCount","firstLineLength","lastLineStart","eol","i","len","length","chr","charCodeAt","getDefaultMetadata","topLevelLanguageId","EMPTY_LINE_TOKENS","Uint32Array","buffer","MultilineTokensBuilder","constructor","tokens","add","lineNumber","lineTokens","last","lastLineNumber","startLineNumber","push","MultilineTokens","SparseEncodedTokens","_tokens","_tokenCount","toString","pieces","_getDeltaLine","_getStartCharacter","_getEndCharacter","join","getMaxDeltaLine","tokenCount","_getTokenCount","getRange","startChar","maxDeltaLine","endChar","tokenIndex","isEmpty","getLineTokens","deltaLine","low","high","mid","Math","floor","midDeltaLine","min","max","LineTokens2","subarray","clear","removeTokens","startDeltaLine","endDeltaLine","newTokenCount","hasDeletedTokens","firstDeltaLine","srcOffset","tokenDeltaLine","tokenStartCharacter","tokenEndCharacter","tokenMetadata","destOffset","split","aTokens","bTokens","destTokens","destFirstDeltaLine","acceptDeleteRange","horizontalShiftForFirstLineTokens","startCharacter","endCharacter","deletedLineCount","Error","acceptInsertText","character","lastLineLength","firstCharCode","isInsertingPreciselyOneWordCharacter","offset","tokenLength","getCount","getStartCharacter","getEndCharacter","getMetadata","MultilineTokens2","endLineNumber","_updateEndLineNumber","deltaRange","startColumn","endColumn","range","startLineIndex","endLineIndex","a","b","bDeltaLine","applyEdit","acceptEdit","_acceptDeleteRange","_acceptInsertText","firstLineIndex","lastLineIndex","deletedLinesCount","tokenMaxDeltaLine","deletedBefore","position","lineIndex","column","toUint32Array","arr","TokensStore2","languageIdCodec","_pieces","_isComplete","_languageIdCodec","flush","set","isComplete","setPartial","_range","_firstRange","_lastRange","plusRange","insertPosition","piece","index","splice","arrayInsert","addSemanticTokens","pieceIndex","_findFirstPieceWithLine","aLen","bLen","aIndex","result","resultLen","lastEndOffset","emitToken","endOffset","metadata","bIndex","bStartCharacter","bEndCharacter","bMetadata","bMask","aMask","getEndOffset","getStartOffset","aMergeIndex","getLineContent","TokensStore","_lineTokens","_len","getTokens","lineText","rawLineTokens","encodeLanguageId","_massageTokens","lineTextLength","hasDifferentLanguageId","getLanguageId","byteOffset","byteLength","_ensureLine","_deleteLines","start","deleteCount","_insertLines","insertIndex","insertCount","setTokens","checkEquality","oldTokens","_equals","_a","_b","_delete","_deleteEnding","lastLineTokens","_deleteBeginning","_append","_insert","toChIndex","fromChIndex","tokensCount","fromTokenIndex","findIndexInTokensArray","fromTokenStartOffset","fromTokenEndOffset","delta","dest","lastEnd","tokenEndOffset","tmp","_otherTokens","myTokens","otherTokens","otherTokensCount","chIndex","textLength"],"mappings":"AAAA;AACA;AACA;AACA;AACA,OAAO,KAAKA,MAAZ,MAAwB,gCAAxB;AACA,SAASC,UAAT,QAA2B,uBAA3B;AACA,SAASC,QAAT,QAAyB,qBAAzB;AACA,SAASC,KAAT,QAAsB,kBAAtB;AACA,SAASC,aAAT,QAA8B,aAA9B;AACA,OAAO,SAASC,QAAT,CAAkBC,IAAlB,EAAwB;AAC3B,MAAIC,QAAQ,GAAG,CAAf;AACA,MAAIC,eAAe,GAAG,CAAtB;AACA,MAAIC,aAAa,GAAG,CAApB;AACA,MAAIC,GAAG,GAAG;AAAE;AAAZ;;AACA,OAAK,IAAIC,CAAC,GAAG,CAAR,EAAWC,GAAG,GAAGN,IAAI,CAACO,MAA3B,EAAmCF,CAAC,GAAGC,GAAvC,EAA4CD,CAAC,EAA7C,EAAiD;AAC7C,UAAMG,GAAG,GAAGR,IAAI,CAACS,UAAL,CAAgBJ,CAAhB,CAAZ;;AACA,QAAIG,GAAG,KAAK;AAAG;AAAf,MAAqC;AACjC,UAAIP,QAAQ,KAAK,CAAjB,EAAoB;AAChBC,QAAAA,eAAe,GAAGG,CAAlB;AACH;;AACDJ,MAAAA,QAAQ;;AACR,UAAII,CAAC,GAAG,CAAJ,GAAQC,GAAR,IAAeN,IAAI,CAACS,UAAL,CAAgBJ,CAAC,GAAG,CAApB,MAA2B;AAAG;AAAjD,QAAiE;AAC7D;AACAD,QAAAA,GAAG,IAAI;AAAE;AAAT;AACAC,QAAAA,CAAC,GAH4D,CAGxD;AACR,OAJD,MAKK;AACD;AACAD,QAAAA,GAAG,IAAI;AAAE;AAAT;AACH;;AACDD,MAAAA,aAAa,GAAGE,CAAC,GAAG,CAApB;AACH,KAfD,MAgBK,IAAIG,GAAG,KAAK;AAAG;AAAf,MAA+B;AAChC;AACAJ,MAAAA,GAAG,IAAI;AAAE;AAAT;;AACA,UAAIH,QAAQ,KAAK,CAAjB,EAAoB;AAChBC,QAAAA,eAAe,GAAGG,CAAlB;AACH;;AACDJ,MAAAA,QAAQ;AACRE,MAAAA,aAAa,GAAGE,CAAC,GAAG,CAApB;AACH;AACJ;;AACD,MAAIJ,QAAQ,KAAK,CAAjB,EAAoB;AAChBC,IAAAA,eAAe,GAAGF,IAAI,CAACO,MAAvB;AACH;;AACD,SAAO,CAACN,QAAD,EAAWC,eAAX,EAA4BF,IAAI,CAACO,MAAL,GAAcJ,aAA1C,EAAyDC,GAAzD,CAAP;AACH;;AACD,SAASM,kBAAT,CAA4BC,kBAA5B,EAAgD;AAC5C,SAAO,CAAEA,kBAAkB,IAAI;AAAE;AAAzB,IACD;AAAE;AAAF,KAAiB;AAAE;AADlB,IAED;AAAE;AAAF,KAAgB;AAAG;AAFlB,IAGD;AAAE;AAAF,KAA6B;AAAG;AAH/B,IAID;AAAE;AAAF,KAA6B;AAAG;AAJhC,QAI8D,CAJrE;AAKH;;AACD,MAAMC,iBAAiB,GAAI,IAAIC,WAAJ,CAAgB,CAAhB,CAAD,CAAqBC,MAA/C;AACA,OAAO,MAAMC,sBAAN,CAA6B;AAChCC,EAAAA,WAAW,GAAG;AACV,SAAKC,MAAL,GAAc,EAAd;AACH;;AACDC,EAAAA,GAAG,CAACC,UAAD,EAAaC,UAAb,EAAyB;AACxB,QAAI,KAAKH,MAAL,CAAYV,MAAZ,GAAqB,CAAzB,EAA4B;AACxB,YAAMc,IAAI,GAAG,KAAKJ,MAAL,CAAY,KAAKA,MAAL,CAAYV,MAAZ,GAAqB,CAAjC,CAAb;AACA,YAAMe,cAAc,GAAGD,IAAI,CAACE,eAAL,GAAuBF,IAAI,CAACJ,MAAL,CAAYV,MAAnC,GAA4C,CAAnE;;AACA,UAAIe,cAAc,GAAG,CAAjB,KAAuBH,UAA3B,EAAuC;AACnC;AACAE,QAAAA,IAAI,CAACJ,MAAL,CAAYO,IAAZ,CAAiBJ,UAAjB;AACA;AACH;AACJ;;AACD,SAAKH,MAAL,CAAYO,IAAZ,CAAiB,IAAIC,eAAJ,CAAoBN,UAApB,EAAgC,CAACC,UAAD,CAAhC,CAAjB;AACH;;AAf+B;AAiBpC,OAAO,MAAMM,mBAAN,CAA0B;AAC7BV,EAAAA,WAAW,CAACC,MAAD,EAAS;AAChB,SAAKU,OAAL,GAAeV,MAAf;AACA,SAAKW,WAAL,GAAmBX,MAAM,CAACV,MAAP,GAAgB,CAAnC;AACH;;AACDsB,EAAAA,QAAQ,CAACN,eAAD,EAAkB;AACtB,QAAIO,MAAM,GAAG,EAAb;;AACA,SAAK,IAAIzB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKuB,WAAzB,EAAsCvB,CAAC,EAAvC,EAA2C;AACvCyB,MAAAA,MAAM,CAACN,IAAP,CAAa,IAAG,KAAKO,aAAL,CAAmB1B,CAAnB,IAAwBkB,eAAgB,IAAG,KAAKS,kBAAL,CAAwB3B,CAAxB,CAA2B,IAAG,KAAK4B,gBAAL,CAAsB5B,CAAtB,CAAyB,GAAlH;AACH;;AACD,WAAQ,IAAGyB,MAAM,CAACI,IAAP,CAAY,GAAZ,CAAiB,GAA5B;AACH;;AACDC,EAAAA,eAAe,GAAG;AACd,UAAMC,UAAU,GAAG,KAAKC,cAAL,EAAnB;;AACA,QAAID,UAAU,KAAK,CAAnB,EAAsB;AAClB,aAAO,CAAC,CAAR;AACH;;AACD,WAAO,KAAKL,aAAL,CAAmBK,UAAU,GAAG,CAAhC,CAAP;AACH;;AACDE,EAAAA,QAAQ,GAAG;AACP,UAAMF,UAAU,GAAG,KAAKC,cAAL,EAAnB;;AACA,QAAID,UAAU,KAAK,CAAnB,EAAsB;AAClB,aAAO,IAAP;AACH;;AACD,UAAMG,SAAS,GAAG,KAAKP,kBAAL,CAAwB,CAAxB,CAAlB;;AACA,UAAMQ,YAAY,GAAG,KAAKT,aAAL,CAAmBK,UAAU,GAAG,CAAhC,CAArB;;AACA,UAAMK,OAAO,GAAG,KAAKR,gBAAL,CAAsBG,UAAU,GAAG,CAAnC,CAAhB;;AACA,WAAO,IAAIvC,KAAJ,CAAU,CAAV,EAAa0C,SAAS,GAAG,CAAzB,EAA4BC,YAA5B,EAA0CC,OAAO,GAAG,CAApD,CAAP;AACH;;AACDJ,EAAAA,cAAc,GAAG;AACb,WAAO,KAAKT,WAAZ;AACH;;AACDG,EAAAA,aAAa,CAACW,UAAD,EAAa;AACtB,WAAO,KAAKf,OAAL,CAAa,IAAIe,UAAjB,CAAP;AACH;;AACDV,EAAAA,kBAAkB,CAACU,UAAD,EAAa;AAC3B,WAAO,KAAKf,OAAL,CAAa,IAAIe,UAAJ,GAAiB,CAA9B,CAAP;AACH;;AACDT,EAAAA,gBAAgB,CAACS,UAAD,EAAa;AACzB,WAAO,KAAKf,OAAL,CAAa,IAAIe,UAAJ,GAAiB,CAA9B,CAAP;AACH;;AACDC,EAAAA,OAAO,GAAG;AACN,WAAQ,KAAKN,cAAL,OAA0B,CAAlC;AACH;;AACDO,EAAAA,aAAa,CAACC,SAAD,EAAY;AACrB,QAAIC,GAAG,GAAG,CAAV;AACA,QAAIC,IAAI,GAAG,KAAKV,cAAL,KAAwB,CAAnC;;AACA,WAAOS,GAAG,GAAGC,IAAb,EAAmB;AACf,YAAMC,GAAG,GAAGF,GAAG,GAAGG,IAAI,CAACC,KAAL,CAAW,CAACH,IAAI,GAAGD,GAAR,IAAe,CAA1B,CAAlB;;AACA,YAAMK,YAAY,GAAG,KAAKpB,aAAL,CAAmBiB,GAAnB,CAArB;;AACA,UAAIG,YAAY,GAAGN,SAAnB,EAA8B;AAC1BC,QAAAA,GAAG,GAAGE,GAAG,GAAG,CAAZ;AACH,OAFD,MAGK,IAAIG,YAAY,GAAGN,SAAnB,EAA8B;AAC/BE,QAAAA,IAAI,GAAGC,GAAG,GAAG,CAAb;AACH,OAFI,MAGA;AACD,YAAII,GAAG,GAAGJ,GAAV;;AACA,eAAOI,GAAG,GAAGN,GAAN,IAAa,KAAKf,aAAL,CAAmBqB,GAAG,GAAG,CAAzB,MAAgCP,SAApD,EAA+D;AAC3DO,UAAAA,GAAG;AACN;;AACD,YAAIC,GAAG,GAAGL,GAAV;;AACA,eAAOK,GAAG,GAAGN,IAAN,IAAc,KAAKhB,aAAL,CAAmBsB,GAAG,GAAG,CAAzB,MAAgCR,SAArD,EAAgE;AAC5DQ,UAAAA,GAAG;AACN;;AACD,eAAO,IAAIC,WAAJ,CAAgB,KAAK3B,OAAL,CAAa4B,QAAb,CAAsB,IAAIH,GAA1B,EAA+B,IAAIC,GAAJ,GAAU,CAAzC,CAAhB,CAAP;AACH;AACJ;;AACD,QAAI,KAAKtB,aAAL,CAAmBe,GAAnB,MAA4BD,SAAhC,EAA2C;AACvC,aAAO,IAAIS,WAAJ,CAAgB,KAAK3B,OAAL,CAAa4B,QAAb,CAAsB,IAAIT,GAA1B,EAA+B,IAAIA,GAAJ,GAAU,CAAzC,CAAhB,CAAP;AACH;;AACD,WAAO,IAAP;AACH;;AACDU,EAAAA,KAAK,GAAG;AACJ,SAAK5B,WAAL,GAAmB,CAAnB;AACH;;AACD6B,EAAAA,YAAY,CAACC,cAAD,EAAiBnB,SAAjB,EAA4BoB,YAA5B,EAA0ClB,OAA1C,EAAmD;AAC3D,UAAMxB,MAAM,GAAG,KAAKU,OAApB;AACA,UAAMS,UAAU,GAAG,KAAKR,WAAxB;AACA,QAAIgC,aAAa,GAAG,CAApB;AACA,QAAIC,gBAAgB,GAAG,KAAvB;AACA,QAAIC,cAAc,GAAG,CAArB;;AACA,SAAK,IAAIzD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG+B,UAApB,EAAgC/B,CAAC,EAAjC,EAAqC;AACjC,YAAM0D,SAAS,GAAG,IAAI1D,CAAtB;AACA,YAAM2D,cAAc,GAAG/C,MAAM,CAAC8C,SAAD,CAA7B;AACA,YAAME,mBAAmB,GAAGhD,MAAM,CAAC8C,SAAS,GAAG,CAAb,CAAlC;AACA,YAAMG,iBAAiB,GAAGjD,MAAM,CAAC8C,SAAS,GAAG,CAAb,CAAhC;AACA,YAAMI,aAAa,GAAGlD,MAAM,CAAC8C,SAAS,GAAG,CAAb,CAA5B;;AACA,UAAI,CAACC,cAAc,GAAGN,cAAjB,IAAoCM,cAAc,KAAKN,cAAnB,IAAqCQ,iBAAiB,IAAI3B,SAA/F,MACIyB,cAAc,GAAGL,YAAjB,IAAkCK,cAAc,KAAKL,YAAnB,IAAmCM,mBAAmB,IAAIxB,OADhG,CAAJ,EAC+G;AAC3GoB,QAAAA,gBAAgB,GAAG,IAAnB;AACH,OAHD,MAIK;AACD,YAAID,aAAa,KAAK,CAAtB,EAAyB;AACrBE,UAAAA,cAAc,GAAGE,cAAjB;AACH;;AACD,YAAIH,gBAAJ,EAAsB;AAClB;AACA,gBAAMO,UAAU,GAAG,IAAIR,aAAvB;AACA3C,UAAAA,MAAM,CAACmD,UAAD,CAAN,GAAqBJ,cAAc,GAAGF,cAAtC;AACA7C,UAAAA,MAAM,CAACmD,UAAU,GAAG,CAAd,CAAN,GAAyBH,mBAAzB;AACAhD,UAAAA,MAAM,CAACmD,UAAU,GAAG,CAAd,CAAN,GAAyBF,iBAAzB;AACAjD,UAAAA,MAAM,CAACmD,UAAU,GAAG,CAAd,CAAN,GAAyBD,aAAzB;AACH;;AACDP,QAAAA,aAAa;AAChB;AACJ;;AACD,SAAKhC,WAAL,GAAmBgC,aAAnB;AACA,WAAOE,cAAP;AACH;;AACDO,EAAAA,KAAK,CAACX,cAAD,EAAiBnB,SAAjB,EAA4BoB,YAA5B,EAA0ClB,OAA1C,EAAmD;AACpD,UAAMxB,MAAM,GAAG,KAAKU,OAApB;AACA,UAAMS,UAAU,GAAG,KAAKR,WAAxB;AACA,QAAI0C,OAAO,GAAG,EAAd;AACA,QAAIC,OAAO,GAAG,EAAd;AACA,QAAIC,UAAU,GAAGF,OAAjB;AACA,QAAIF,UAAU,GAAG,CAAjB;AACA,QAAIK,kBAAkB,GAAG,CAAzB;;AACA,SAAK,IAAIpE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG+B,UAApB,EAAgC/B,CAAC,EAAjC,EAAqC;AACjC,YAAM0D,SAAS,GAAG,IAAI1D,CAAtB;AACA,YAAM2D,cAAc,GAAG/C,MAAM,CAAC8C,SAAD,CAA7B;AACA,YAAME,mBAAmB,GAAGhD,MAAM,CAAC8C,SAAS,GAAG,CAAb,CAAlC;AACA,YAAMG,iBAAiB,GAAGjD,MAAM,CAAC8C,SAAS,GAAG,CAAb,CAAhC;AACA,YAAMI,aAAa,GAAGlD,MAAM,CAAC8C,SAAS,GAAG,CAAb,CAA5B;;AACA,UAAKC,cAAc,GAAGN,cAAjB,IAAoCM,cAAc,KAAKN,cAAnB,IAAqCQ,iBAAiB,IAAI3B,SAAnG,EAAgH;AAC5G,YAAKyB,cAAc,GAAGL,YAAjB,IAAkCK,cAAc,KAAKL,YAAnB,IAAmCM,mBAAmB,IAAIxB,OAAjG,EAA4G;AACxG;AACA;AACH,SAHD,MAIK;AACD;AACA,cAAI+B,UAAU,KAAKD,OAAnB,EAA4B;AACxB;AACAC,YAAAA,UAAU,GAAGD,OAAb;AACAH,YAAAA,UAAU,GAAG,CAAb;AACAK,YAAAA,kBAAkB,GAAGT,cAArB;AACH;AACJ;AACJ;;AACDQ,MAAAA,UAAU,CAACJ,UAAU,EAAX,CAAV,GAA2BJ,cAAc,GAAGS,kBAA5C;AACAD,MAAAA,UAAU,CAACJ,UAAU,EAAX,CAAV,GAA2BH,mBAA3B;AACAO,MAAAA,UAAU,CAACJ,UAAU,EAAX,CAAV,GAA2BF,iBAA3B;AACAM,MAAAA,UAAU,CAACJ,UAAU,EAAX,CAAV,GAA2BD,aAA3B;AACH;;AACD,WAAO,CAAC,IAAIzC,mBAAJ,CAAwB,IAAIb,WAAJ,CAAgByD,OAAhB,CAAxB,CAAD,EAAoD,IAAI5C,mBAAJ,CAAwB,IAAIb,WAAJ,CAAgB0D,OAAhB,CAAxB,CAApD,EAAuGE,kBAAvG,CAAP;AACH;;AACDC,EAAAA,iBAAiB,CAACC,iCAAD,EAAoCjB,cAApC,EAAoDkB,cAApD,EAAoEjB,YAApE,EAAkFkB,YAAlF,EAAgG;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAM5D,MAAM,GAAG,KAAKU,OAApB;AACA,UAAMS,UAAU,GAAG,KAAKR,WAAxB;AACA,UAAMkD,gBAAgB,GAAInB,YAAY,GAAGD,cAAzC;AACA,QAAIE,aAAa,GAAG,CAApB;AACA,QAAIC,gBAAgB,GAAG,KAAvB;;AACA,SAAK,IAAIxD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG+B,UAApB,EAAgC/B,CAAC,EAAjC,EAAqC;AACjC,YAAM0D,SAAS,GAAG,IAAI1D,CAAtB;AACA,UAAI2D,cAAc,GAAG/C,MAAM,CAAC8C,SAAD,CAA3B;AACA,UAAIE,mBAAmB,GAAGhD,MAAM,CAAC8C,SAAS,GAAG,CAAb,CAAhC;AACA,UAAIG,iBAAiB,GAAGjD,MAAM,CAAC8C,SAAS,GAAG,CAAb,CAA9B;AACA,YAAMI,aAAa,GAAGlD,MAAM,CAAC8C,SAAS,GAAG,CAAb,CAA5B;;AACA,UAAIC,cAAc,GAAGN,cAAjB,IAAoCM,cAAc,KAAKN,cAAnB,IAAqCQ,iBAAiB,IAAIU,cAAlG,EAAmH;AAC/G;AACA;AACAhB,QAAAA,aAAa;AACb;AACH,OALD,MAMK,IAAII,cAAc,KAAKN,cAAnB,IAAqCO,mBAAmB,GAAGW,cAA/D,EAA+E;AAChF;AACA;AACA,YAAIZ,cAAc,KAAKL,YAAnB,IAAmCO,iBAAiB,GAAGW,YAA3D,EAAyE;AACrE;AACA;AACAX,UAAAA,iBAAiB,IAAKW,YAAY,GAAGD,cAArC;AACH,SAJD,MAKK;AACD;AACA;AACA;AACAV,UAAAA,iBAAiB,GAAGU,cAApB;AACH;AACJ,OAdI,MAeA,IAAIZ,cAAc,KAAKN,cAAnB,IAAqCO,mBAAmB,KAAKW,cAAjE,EAAiF;AAClF;AACA,YAAIZ,cAAc,KAAKL,YAAnB,IAAmCO,iBAAiB,GAAGW,YAA3D,EAAyE;AACrE;AACA;AACAX,UAAAA,iBAAiB,IAAKW,YAAY,GAAGD,cAArC;AACH,SAJD,MAKK;AACD;AACA;AACA;AACAf,UAAAA,gBAAgB,GAAG,IAAnB;AACA;AACH;AACJ,OAdI,MAeA,IAAIG,cAAc,GAAGL,YAAjB,IAAkCK,cAAc,KAAKL,YAAnB,IAAmCM,mBAAmB,GAAGY,YAA/F,EAA8G;AAC/G;AACA,YAAIb,cAAc,KAAKL,YAAnB,IAAmCO,iBAAiB,GAAGW,YAA3D,EAAyE;AACrE;AACA;AACA,cAAIb,cAAc,KAAKN,cAAvB,EAAuC;AACnC;AACA;AACAO,YAAAA,mBAAmB,GAAGW,cAAtB;AACAV,YAAAA,iBAAiB,GAAGD,mBAAmB,IAAIC,iBAAiB,GAAGW,YAAxB,CAAvC;AACH,WALD,MAMK;AACD;AACA;AACAZ,YAAAA,mBAAmB,GAAG,CAAtB;AACAC,YAAAA,iBAAiB,GAAGD,mBAAmB,IAAIC,iBAAiB,GAAGW,YAAxB,CAAvC;AACH;AACJ,SAfD,MAgBK;AACD;AACA;AACA;AACAhB,UAAAA,gBAAgB,GAAG,IAAnB;AACA;AACH;AACJ,OAzBI,MA0BA,IAAIG,cAAc,GAAGL,YAArB,EAAmC;AACpC;AACA,YAAImB,gBAAgB,KAAK,CAArB,IAA0B,CAACjB,gBAA/B,EAAiD;AAC7C;AACAD,UAAAA,aAAa,GAAGxB,UAAhB;AACA;AACH;;AACD4B,QAAAA,cAAc,IAAIc,gBAAlB;AACH,OARI,MASA,IAAId,cAAc,KAAKL,YAAnB,IAAmCM,mBAAmB,IAAIY,YAA9D,EAA4E;AAC7E;AACA,YAAIF,iCAAiC,IAAIX,cAAc,KAAK,CAA5D,EAA+D;AAC3DC,UAAAA,mBAAmB,IAAIU,iCAAvB;AACAT,UAAAA,iBAAiB,IAAIS,iCAArB;AACH;;AACDX,QAAAA,cAAc,IAAIc,gBAAlB;AACAb,QAAAA,mBAAmB,IAAKY,YAAY,GAAGD,cAAvC;AACAV,QAAAA,iBAAiB,IAAKW,YAAY,GAAGD,cAArC;AACH,OATI,MAUA;AACD,cAAM,IAAIG,KAAJ,CAAW,eAAX,CAAN;AACH;;AACD,YAAMX,UAAU,GAAG,IAAIR,aAAvB;AACA3C,MAAAA,MAAM,CAACmD,UAAD,CAAN,GAAqBJ,cAArB;AACA/C,MAAAA,MAAM,CAACmD,UAAU,GAAG,CAAd,CAAN,GAAyBH,mBAAzB;AACAhD,MAAAA,MAAM,CAACmD,UAAU,GAAG,CAAd,CAAN,GAAyBF,iBAAzB;AACAjD,MAAAA,MAAM,CAACmD,UAAU,GAAG,CAAd,CAAN,GAAyBD,aAAzB;AACAP,MAAAA,aAAa;AAChB;;AACD,SAAKhC,WAAL,GAAmBgC,aAAnB;AACH;;AACDoB,EAAAA,gBAAgB,CAACnC,SAAD,EAAYoC,SAAZ,EAAuBhF,QAAvB,EAAiCC,eAAjC,EAAkDgF,cAAlD,EAAkEC,aAAlE,EAAiF;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAMC,oCAAoC,GAAInF,QAAQ,KAAK,CAAb,IACvCC,eAAe,KAAK,CADmB,KAErCiF,aAAa,IAAI;AAAG;AAApB,OAAoCA,aAAa,IAAI;AAAG;AAAzD,OACIA,aAAa,IAAI;AAAG;AAApB,OAA+BA,aAAa,IAAI;AAAG;AADvD,OAEIA,aAAa,IAAI;AAAG;AAApB,OAA+BA,aAAa,IAAI;AAAI;AAJlB,KAA9C;AAKA,UAAMlE,MAAM,GAAG,KAAKU,OAApB;AACA,UAAMS,UAAU,GAAG,KAAKR,WAAxB;;AACA,SAAK,IAAIvB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG+B,UAApB,EAAgC/B,CAAC,EAAjC,EAAqC;AACjC,YAAMgF,MAAM,GAAG,IAAIhF,CAAnB;AACA,UAAI2D,cAAc,GAAG/C,MAAM,CAACoE,MAAD,CAA3B;AACA,UAAIpB,mBAAmB,GAAGhD,MAAM,CAACoE,MAAM,GAAG,CAAV,CAAhC;AACA,UAAInB,iBAAiB,GAAGjD,MAAM,CAACoE,MAAM,GAAG,CAAV,CAA9B;;AACA,UAAIrB,cAAc,GAAGnB,SAAjB,IAA+BmB,cAAc,KAAKnB,SAAnB,IAAgCqB,iBAAiB,GAAGe,SAAvF,EAAmG;AAC/F;AACA;AACA;AACH,OAJD,MAKK,IAAIjB,cAAc,KAAKnB,SAAnB,IAAgCqB,iBAAiB,KAAKe,SAA1D,EAAqE;AACtE;AACA;AACA,YAAIG,oCAAJ,EAA0C;AACtClB,UAAAA,iBAAiB,IAAI,CAArB;AACH,SAFD,MAGK;AACD;AACH;AACJ,OATI,MAUA,IAAIF,cAAc,KAAKnB,SAAnB,IAAgCoB,mBAAmB,GAAGgB,SAAtD,IAAmEA,SAAS,GAAGf,iBAAnF,EAAsG;AACvG;AACA,YAAIjE,QAAQ,KAAK,CAAjB,EAAoB;AAChB;AACAiE,UAAAA,iBAAiB,IAAIhE,eAArB;AACH,SAHD,MAIK;AACD;AACAgE,UAAAA,iBAAiB,GAAGe,SAApB;AACH;AACJ,OAVI,MAWA;AACD;AACA,YAAIjB,cAAc,KAAKnB,SAAnB,IAAgCoB,mBAAmB,KAAKgB,SAA5D,EAAuE;AACnE;AACA;AACA;AACA,cAAIG,oCAAJ,EAA0C;AACtC;AACH;AACJ,SATA,CAUD;;;AACA,YAAIpB,cAAc,KAAKnB,SAAvB,EAAkC;AAC9BmB,UAAAA,cAAc,IAAI/D,QAAlB,CAD8B,CAE9B;;AACA,cAAIA,QAAQ,KAAK,CAAjB,EAAoB;AAChBgE,YAAAA,mBAAmB,IAAI/D,eAAvB;AACAgE,YAAAA,iBAAiB,IAAIhE,eAArB;AACH,WAHD,MAIK;AACD,kBAAMoF,WAAW,GAAGpB,iBAAiB,GAAGD,mBAAxC;AACAA,YAAAA,mBAAmB,GAAGiB,cAAc,IAAIjB,mBAAmB,GAAGgB,SAA1B,CAApC;AACAf,YAAAA,iBAAiB,GAAGD,mBAAmB,GAAGqB,WAA1C;AACH;AACJ,SAZD,MAaK;AACDtB,UAAAA,cAAc,IAAI/D,QAAlB;AACH;AACJ;;AACDgB,MAAAA,MAAM,CAACoE,MAAD,CAAN,GAAiBrB,cAAjB;AACA/C,MAAAA,MAAM,CAACoE,MAAM,GAAG,CAAV,CAAN,GAAqBpB,mBAArB;AACAhD,MAAAA,MAAM,CAACoE,MAAM,GAAG,CAAV,CAAN,GAAqBnB,iBAArB;AACH;AACJ;;AAzX4B;AA2XjC,OAAO,MAAMZ,WAAN,CAAkB;AACrBtC,EAAAA,WAAW,CAACC,MAAD,EAAS;AAChB,SAAKU,OAAL,GAAeV,MAAf;AACH;;AACDsE,EAAAA,QAAQ,GAAG;AACP,WAAO,KAAK5D,OAAL,CAAapB,MAAb,GAAsB,CAA7B;AACH;;AACDiF,EAAAA,iBAAiB,CAAC9C,UAAD,EAAa;AAC1B,WAAO,KAAKf,OAAL,CAAa,IAAIe,UAAJ,GAAiB,CAA9B,CAAP;AACH;;AACD+C,EAAAA,eAAe,CAAC/C,UAAD,EAAa;AACxB,WAAO,KAAKf,OAAL,CAAa,IAAIe,UAAJ,GAAiB,CAA9B,CAAP;AACH;;AACDgD,EAAAA,WAAW,CAAChD,UAAD,EAAa;AACpB,WAAO,KAAKf,OAAL,CAAa,IAAIe,UAAJ,GAAiB,CAA9B,CAAP;AACH;;AAfoB;AAiBzB,OAAO,MAAMiD,gBAAN,CAAuB;AAC1B3E,EAAAA,WAAW,CAACO,eAAD,EAAkBN,MAAlB,EAA0B;AACjC,SAAKM,eAAL,GAAuBA,eAAvB;AACA,SAAKN,MAAL,GAAcA,MAAd;AACA,SAAK2E,aAAL,GAAqB,KAAKrE,eAAL,GAAuB,KAAKN,MAAL,CAAYkB,eAAZ,EAA5C;AACH;;AACDN,EAAAA,QAAQ,GAAG;AACP,WAAO,KAAKZ,MAAL,CAAYY,QAAZ,CAAqB,KAAKN,eAA1B,CAAP;AACH;;AACDsE,EAAAA,oBAAoB,GAAG;AACnB,SAAKD,aAAL,GAAqB,KAAKrE,eAAL,GAAuB,KAAKN,MAAL,CAAYkB,eAAZ,EAA5C;AACH;;AACDQ,EAAAA,OAAO,GAAG;AACN,WAAO,KAAK1B,MAAL,CAAY0B,OAAZ,EAAP;AACH;;AACDC,EAAAA,aAAa,CAACzB,UAAD,EAAa;AACtB,QAAI,KAAKI,eAAL,IAAwBJ,UAAxB,IAAsCA,UAAU,IAAI,KAAKyE,aAA7D,EAA4E;AACxE,aAAO,KAAK3E,MAAL,CAAY2B,aAAZ,CAA0BzB,UAAU,GAAG,KAAKI,eAA5C,CAAP;AACH;;AACD,WAAO,IAAP;AACH;;AACDe,EAAAA,QAAQ,GAAG;AACP,UAAMwD,UAAU,GAAG,KAAK7E,MAAL,CAAYqB,QAAZ,EAAnB;;AACA,QAAI,CAACwD,UAAL,EAAiB;AACb,aAAOA,UAAP;AACH;;AACD,WAAO,IAAIjG,KAAJ,CAAU,KAAK0B,eAAL,GAAuBuE,UAAU,CAACvE,eAA5C,EAA6DuE,UAAU,CAACC,WAAxE,EAAqF,KAAKxE,eAAL,GAAuBuE,UAAU,CAACF,aAAvH,EAAsIE,UAAU,CAACE,SAAjJ,CAAP;AACH;;AACDvC,EAAAA,YAAY,CAACwC,KAAD,EAAQ;AAChB,UAAMC,cAAc,GAAGD,KAAK,CAAC1E,eAAN,GAAwB,KAAKA,eAApD;AACA,UAAM4E,YAAY,GAAGF,KAAK,CAACL,aAAN,GAAsB,KAAKrE,eAAhD;AACA,SAAKA,eAAL,IAAwB,KAAKN,MAAL,CAAYwC,YAAZ,CAAyByC,cAAzB,EAAyCD,KAAK,CAACF,WAAN,GAAoB,CAA7D,EAAgEI,YAAhE,EAA8EF,KAAK,CAACD,SAAN,GAAkB,CAAhG,CAAxB;;AACA,SAAKH,oBAAL;AACH;;AACDxB,EAAAA,KAAK,CAAC4B,KAAD,EAAQ;AACT;AACA;AACA;AACA,UAAMC,cAAc,GAAGD,KAAK,CAAC1E,eAAN,GAAwB,KAAKA,eAApD;AACA,UAAM4E,YAAY,GAAGF,KAAK,CAACL,aAAN,GAAsB,KAAKrE,eAAhD;AACA,UAAM,CAAC6E,CAAD,EAAIC,CAAJ,EAAOC,UAAP,IAAqB,KAAKrF,MAAL,CAAYoD,KAAZ,CAAkB6B,cAAlB,EAAkCD,KAAK,CAACF,WAAN,GAAoB,CAAtD,EAAyDI,YAAzD,EAAuEF,KAAK,CAACD,SAAN,GAAkB,CAAzF,CAA3B;AACA,WAAO,CAAC,IAAIL,gBAAJ,CAAqB,KAAKpE,eAA1B,EAA2C6E,CAA3C,CAAD,EAAgD,IAAIT,gBAAJ,CAAqB,KAAKpE,eAAL,GAAuB+E,UAA5C,EAAwDD,CAAxD,CAAhD,CAAP;AACH;;AACDE,EAAAA,SAAS,CAACN,KAAD,EAAQjG,IAAR,EAAc;AACnB,UAAM,CAACC,QAAD,EAAWC,eAAX,EAA4BgF,cAA5B,IAA8CnF,QAAQ,CAACC,IAAD,CAA5D;AACA,SAAKwG,UAAL,CAAgBP,KAAhB,EAAuBhG,QAAvB,EAAiCC,eAAjC,EAAkDgF,cAAlD,EAAkElF,IAAI,CAACO,MAAL,GAAc,CAAd,GAAkBP,IAAI,CAACS,UAAL,CAAgB,CAAhB,CAAlB,GAAuC;AAAE;AAA3G;AACH;;AACD+F,EAAAA,UAAU,CAACP,KAAD,EAAQhG,QAAR,EAAkBC,eAAlB,EAAmCgF,cAAnC,EAAmDC,aAAnD,EAAkE;AACxE,SAAKsB,kBAAL,CAAwBR,KAAxB;;AACA,SAAKS,iBAAL,CAAuB,IAAI9G,QAAJ,CAAaqG,KAAK,CAAC1E,eAAnB,EAAoC0E,KAAK,CAACF,WAA1C,CAAvB,EAA+E9F,QAA/E,EAAyFC,eAAzF,EAA0GgF,cAA1G,EAA0HC,aAA1H;;AACA,SAAKU,oBAAL;AACH;;AACDY,EAAAA,kBAAkB,CAACR,KAAD,EAAQ;AACtB,QAAIA,KAAK,CAAC1E,eAAN,KAA0B0E,KAAK,CAACL,aAAhC,IAAiDK,KAAK,CAACF,WAAN,KAAsBE,KAAK,CAACD,SAAjF,EAA4F;AACxF;AACA;AACH;;AACD,UAAMW,cAAc,GAAGV,KAAK,CAAC1E,eAAN,GAAwB,KAAKA,eAApD;AACA,UAAMqF,aAAa,GAAGX,KAAK,CAACL,aAAN,GAAsB,KAAKrE,eAAjD;;AACA,QAAIqF,aAAa,GAAG,CAApB,EAAuB;AACnB;AACA,YAAMC,iBAAiB,GAAGD,aAAa,GAAGD,cAA1C;AACA,WAAKpF,eAAL,IAAwBsF,iBAAxB;AACA;AACH;;AACD,UAAMC,iBAAiB,GAAG,KAAK7F,MAAL,CAAYkB,eAAZ,EAA1B;;AACA,QAAIwE,cAAc,IAAIG,iBAAiB,GAAG,CAA1C,EAA6C;AACzC;AACA;AACH;;AACD,QAAIH,cAAc,GAAG,CAAjB,IAAsBC,aAAa,IAAIE,iBAAiB,GAAG,CAA/D,EAAkE;AAC9D;AACA,WAAKvF,eAAL,GAAuB,CAAvB;AACA,WAAKN,MAAL,CAAYuC,KAAZ;AACA;AACH;;AACD,QAAImD,cAAc,GAAG,CAArB,EAAwB;AACpB,YAAMI,aAAa,GAAG,CAACJ,cAAvB;AACA,WAAKpF,eAAL,IAAwBwF,aAAxB;AACA,WAAK9F,MAAL,CAAYyD,iBAAZ,CAA8BuB,KAAK,CAACF,WAAN,GAAoB,CAAlD,EAAqD,CAArD,EAAwD,CAAxD,EAA2Da,aAA3D,EAA0EX,KAAK,CAACD,SAAN,GAAkB,CAA5F;AACH,KAJD,MAKK;AACD,WAAK/E,MAAL,CAAYyD,iBAAZ,CAA8B,CAA9B,EAAiCiC,cAAjC,EAAiDV,KAAK,CAACF,WAAN,GAAoB,CAArE,EAAwEa,aAAxE,EAAuFX,KAAK,CAACD,SAAN,GAAkB,CAAzG;AACH;AACJ;;AACDU,EAAAA,iBAAiB,CAACM,QAAD,EAAW/G,QAAX,EAAqBC,eAArB,EAAsCgF,cAAtC,EAAsDC,aAAtD,EAAqE;AAClF,QAAIlF,QAAQ,KAAK,CAAb,IAAkBC,eAAe,KAAK,CAA1C,EAA6C;AACzC;AACA;AACH;;AACD,UAAM+G,SAAS,GAAGD,QAAQ,CAAC7F,UAAT,GAAsB,KAAKI,eAA7C;;AACA,QAAI0F,SAAS,GAAG,CAAhB,EAAmB;AACf;AACA,WAAK1F,eAAL,IAAwBtB,QAAxB;AACA;AACH;;AACD,UAAM6G,iBAAiB,GAAG,KAAK7F,MAAL,CAAYkB,eAAZ,EAA1B;;AACA,QAAI8E,SAAS,IAAIH,iBAAiB,GAAG,CAArC,EAAwC;AACpC;AACA;AACH;;AACD,SAAK7F,MAAL,CAAY+D,gBAAZ,CAA6BiC,SAA7B,EAAwCD,QAAQ,CAACE,MAAT,GAAkB,CAA1D,EAA6DjH,QAA7D,EAAuEC,eAAvE,EAAwFgF,cAAxF,EAAwGC,aAAxG;AACH;;AAtGyB;AAwG9B,OAAO,MAAM1D,eAAN,CAAsB;AACzBT,EAAAA,WAAW,CAACO,eAAD,EAAkBN,MAAlB,EAA0B;AACjC,SAAKM,eAAL,GAAuBA,eAAvB;AACA,SAAKN,MAAL,GAAcA,MAAd;AACH;;AAJwB;;AAM7B,SAASkG,aAAT,CAAuBC,GAAvB,EAA4B;AACxB,MAAIA,GAAG,YAAYvG,WAAnB,EAAgC;AAC5B,WAAOuG,GAAP;AACH,GAFD,MAGK;AACD,WAAO,IAAIvG,WAAJ,CAAgBuG,GAAhB,CAAP;AACH;AACJ;;AACD,OAAO,MAAMC,YAAN,CAAmB;AACtBrG,EAAAA,WAAW,CAACsG,eAAD,EAAkB;AACzB,SAAKC,OAAL,GAAe,EAAf;AACA,SAAKC,WAAL,GAAmB,KAAnB;AACA,SAAKC,gBAAL,GAAwBH,eAAxB;AACH;;AACDI,EAAAA,KAAK,GAAG;AACJ,SAAKH,OAAL,GAAe,EAAf;AACA,SAAKC,WAAL,GAAmB,KAAnB;AACH;;AACD7E,EAAAA,OAAO,GAAG;AACN,WAAQ,KAAK4E,OAAL,CAAahH,MAAb,KAAwB,CAAhC;AACH;;AACDoH,EAAAA,GAAG,CAAC7F,MAAD,EAAS8F,UAAT,EAAqB;AACpB,SAAKL,OAAL,GAAezF,MAAM,IAAI,EAAzB;AACA,SAAK0F,WAAL,GAAmBI,UAAnB;AACH;;AACDC,EAAAA,UAAU,CAACC,MAAD,EAAShG,MAAT,EAAiB;AACvB;AACA,QAAImE,KAAK,GAAG6B,MAAZ;;AACA,QAAIhG,MAAM,CAACvB,MAAP,GAAgB,CAApB,EAAuB;AACnB,YAAMwH,WAAW,GAAGjG,MAAM,CAAC,CAAD,CAAN,CAAUQ,QAAV,EAApB;;AACA,YAAM0F,UAAU,GAAGlG,MAAM,CAACA,MAAM,CAACvB,MAAP,GAAgB,CAAjB,CAAN,CAA0B+B,QAA1B,EAAnB;;AACA,UAAI,CAACyF,WAAD,IAAgB,CAACC,UAArB,EAAiC;AAC7B,eAAOF,MAAP;AACH;;AACD7B,MAAAA,KAAK,GAAG6B,MAAM,CAACG,SAAP,CAAiBF,WAAjB,EAA8BE,SAA9B,CAAwCD,UAAxC,CAAR;AACH;;AACD,QAAIE,cAAc,GAAG,IAArB;;AACA,SAAK,IAAI7H,CAAC,GAAG,CAAR,EAAWC,GAAG,GAAG,KAAKiH,OAAL,CAAahH,MAAnC,EAA2CF,CAAC,GAAGC,GAA/C,EAAoDD,CAAC,EAArD,EAAyD;AACrD,YAAM8H,KAAK,GAAG,KAAKZ,OAAL,CAAalH,CAAb,CAAd;;AACA,UAAI8H,KAAK,CAACvC,aAAN,GAAsBK,KAAK,CAAC1E,eAAhC,EAAiD;AAC7C;AACA;AACH;;AACD,UAAI4G,KAAK,CAAC5G,eAAN,GAAwB0E,KAAK,CAACL,aAAlC,EAAiD;AAC7C;AACA;AACAsC,QAAAA,cAAc,GAAGA,cAAc,IAAI;AAAEE,UAAAA,KAAK,EAAE/H;AAAT,SAAnC;AACA;AACH,OAXoD,CAYrD;;;AACA8H,MAAAA,KAAK,CAAC1E,YAAN,CAAmBwC,KAAnB;;AACA,UAAIkC,KAAK,CAACxF,OAAN,EAAJ,EAAqB;AACjB;AACA,aAAK4E,OAAL,CAAac,MAAb,CAAoBhI,CAApB,EAAuB,CAAvB;;AACAA,QAAAA,CAAC;AACDC,QAAAA,GAAG;AACH;AACH;;AACD,UAAI6H,KAAK,CAACvC,aAAN,GAAsBK,KAAK,CAAC1E,eAAhC,EAAiD;AAC7C;AACA;AACH;;AACD,UAAI4G,KAAK,CAAC5G,eAAN,GAAwB0E,KAAK,CAACL,aAAlC,EAAiD;AAC7C;AACAsC,QAAAA,cAAc,GAAGA,cAAc,IAAI;AAAEE,UAAAA,KAAK,EAAE/H;AAAT,SAAnC;AACA;AACH,OA7BoD,CA8BrD;;;AACA,YAAM,CAAC+F,CAAD,EAAIC,CAAJ,IAAS8B,KAAK,CAAC9D,KAAN,CAAY4B,KAAZ,CAAf;;AACA,UAAIG,CAAC,CAACzD,OAAF,EAAJ,EAAiB;AACb;AACAuF,QAAAA,cAAc,GAAGA,cAAc,IAAI;AAAEE,UAAAA,KAAK,EAAE/H;AAAT,SAAnC;AACA;AACH;;AACD,UAAIgG,CAAC,CAAC1D,OAAF,EAAJ,EAAiB;AACb;AACA;AACH;;AACD,WAAK4E,OAAL,CAAac,MAAb,CAAoBhI,CAApB,EAAuB,CAAvB,EAA0B+F,CAA1B,EAA6BC,CAA7B;;AACAhG,MAAAA,CAAC;AACDC,MAAAA,GAAG;AACH4H,MAAAA,cAAc,GAAGA,cAAc,IAAI;AAAEE,QAAAA,KAAK,EAAE/H;AAAT,OAAnC;AACH;;AACD6H,IAAAA,cAAc,GAAGA,cAAc,IAAI;AAAEE,MAAAA,KAAK,EAAE,KAAKb,OAAL,CAAahH;AAAtB,KAAnC;;AACA,QAAIuB,MAAM,CAACvB,MAAP,GAAgB,CAApB,EAAuB;AACnB,WAAKgH,OAAL,GAAe7H,MAAM,CAAC4I,WAAP,CAAmB,KAAKf,OAAxB,EAAiCW,cAAc,CAACE,KAAhD,EAAuDtG,MAAvD,CAAf;AACH,KA7DsB,CA8DvB;AACA;;;AACA,WAAOmE,KAAP;AACH;;AACD2B,EAAAA,UAAU,GAAG;AACT,WAAO,KAAKJ,WAAZ;AACH;;AACDe,EAAAA,iBAAiB,CAACpH,UAAD,EAAamD,OAAb,EAAsB;AACnC,UAAMxC,MAAM,GAAG,KAAKyF,OAApB;;AACA,QAAIzF,MAAM,CAACvB,MAAP,KAAkB,CAAtB,EAAyB;AACrB,aAAO+D,OAAP;AACH;;AACD,UAAMkE,UAAU,GAAGnB,YAAY,CAACoB,uBAAb,CAAqC3G,MAArC,EAA6CX,UAA7C,CAAnB;;AACA,UAAMoD,OAAO,GAAGzC,MAAM,CAAC0G,UAAD,CAAN,CAAmB5F,aAAnB,CAAiCzB,UAAjC,CAAhB;;AACA,QAAI,CAACoD,OAAL,EAAc;AACV,aAAOD,OAAP;AACH;;AACD,UAAMoE,IAAI,GAAGpE,OAAO,CAACiB,QAAR,EAAb;AACA,UAAMoD,IAAI,GAAGpE,OAAO,CAACgB,QAAR,EAAb;AACA,QAAIqD,MAAM,GAAG,CAAb;AACA,QAAIC,MAAM,GAAG,EAAb;AAAA,QAAiBC,SAAS,GAAG,CAA7B;AACA,QAAIC,aAAa,GAAG,CAApB;;AACA,UAAMC,SAAS,GAAG,CAACC,SAAD,EAAYC,QAAZ,KAAyB;AACvC,UAAID,SAAS,KAAKF,aAAlB,EAAiC;AAC7B;AACH;;AACDA,MAAAA,aAAa,GAAGE,SAAhB;AACAJ,MAAAA,MAAM,CAACC,SAAS,EAAV,CAAN,GAAsBG,SAAtB;AACAJ,MAAAA,MAAM,CAACC,SAAS,EAAV,CAAN,GAAsBI,QAAtB;AACH,KAPD;;AAQA,SAAK,IAAIC,MAAM,GAAG,CAAlB,EAAqBA,MAAM,GAAGR,IAA9B,EAAoCQ,MAAM,EAA1C,EAA8C;AAC1C,YAAMC,eAAe,GAAG7E,OAAO,CAACiB,iBAAR,CAA0B2D,MAA1B,CAAxB;AACA,YAAME,aAAa,GAAG9E,OAAO,CAACkB,eAAR,CAAwB0D,MAAxB,CAAtB;AACA,YAAMG,SAAS,GAAG/E,OAAO,CAACmB,WAAR,CAAoByD,MAApB,CAAlB;AACA,YAAMI,KAAK,GAAG,CAAC,CAAED,SAAS,GAAG;AAAE;AAAf,QAA4C;AAAK;AAAjD,QAAqE,CAAtE,KACPA,SAAS,GAAG;AAAE;AAAf,QAA0C;AAAK;AAA/C,QAAiE,CADzD,KAEPA,SAAS,GAAG;AAAE;AAAf,QAA+C;AAAK;AAApD,QAA2E,CAFnE,KAGPA,SAAS,GAAG;AAAE;AAAf,QAAgD;AAAQ;AAAxD,QAAgF,CAHxE,KAIPA,SAAS,GAAG;AAAG;AAAhB,QAAiD;AAAW;AAA5D,QAAoF,CAJ5E,CAAD,MAIqF,CAJnG;AAKA,YAAME,KAAK,GAAI,CAACD,KAAF,KAAa,CAA3B,CAT0C,CAU1C;;AACA,aAAOX,MAAM,GAAGF,IAAT,IAAiBpE,OAAO,CAACmF,YAAR,CAAqBb,MAArB,KAAgCQ,eAAxD,EAAyE;AACrEJ,QAAAA,SAAS,CAAC1E,OAAO,CAACmF,YAAR,CAAqBb,MAArB,CAAD,EAA+BtE,OAAO,CAACoB,WAAR,CAAoBkD,MAApB,CAA/B,CAAT;AACAA,QAAAA,MAAM;AACT,OAdyC,CAe1C;;;AACA,UAAIA,MAAM,GAAGF,IAAT,IAAiBpE,OAAO,CAACoF,cAAR,CAAuBd,MAAvB,IAAiCQ,eAAtD,EAAuE;AACnEJ,QAAAA,SAAS,CAACI,eAAD,EAAkB9E,OAAO,CAACoB,WAAR,CAAoBkD,MAApB,CAAlB,CAAT;AACH,OAlByC,CAmB1C;;;AACA,aAAOA,MAAM,GAAGF,IAAT,IAAiBpE,OAAO,CAACmF,YAAR,CAAqBb,MAArB,IAA+BS,aAAvD,EAAsE;AAClEL,QAAAA,SAAS,CAAC1E,OAAO,CAACmF,YAAR,CAAqBb,MAArB,CAAD,EAAgCtE,OAAO,CAACoB,WAAR,CAAoBkD,MAApB,IAA8BY,KAA/B,GAAyCF,SAAS,GAAGC,KAApF,CAAT;AACAX,QAAAA,MAAM;AACT;;AACD,UAAIA,MAAM,GAAGF,IAAb,EAAmB;AACfM,QAAAA,SAAS,CAACK,aAAD,EAAiB/E,OAAO,CAACoB,WAAR,CAAoBkD,MAApB,IAA8BY,KAA/B,GAAyCF,SAAS,GAAGC,KAArE,CAAT;;AACA,YAAIjF,OAAO,CAACmF,YAAR,CAAqBb,MAArB,MAAiCS,aAArC,EAAoD;AAChD;AACAT,UAAAA,MAAM;AACT;AACJ,OAND,MAOK;AACD,cAAMe,WAAW,GAAG1G,IAAI,CAACG,GAAL,CAASH,IAAI,CAACI,GAAL,CAAS,CAAT,EAAYuF,MAAM,GAAG,CAArB,CAAT,EAAkCF,IAAI,GAAG,CAAzC,CAApB,CADC,CAED;;AACAM,QAAAA,SAAS,CAACK,aAAD,EAAiB/E,OAAO,CAACoB,WAAR,CAAoBiE,WAApB,IAAmCH,KAApC,GAA8CF,SAAS,GAAGC,KAA1E,CAAT;AACH;AACJ,KA3DkC,CA4DnC;;;AACA,WAAOX,MAAM,GAAGF,IAAhB,EAAsB;AAClBM,MAAAA,SAAS,CAAC1E,OAAO,CAACmF,YAAR,CAAqBb,MAArB,CAAD,EAA+BtE,OAAO,CAACoB,WAAR,CAAoBkD,MAApB,CAA/B,CAAT;AACAA,MAAAA,MAAM;AACT;;AACD,WAAO,IAAIjJ,UAAJ,CAAe,IAAIkB,WAAJ,CAAgBgI,MAAhB,CAAf,EAAwCvE,OAAO,CAACsF,cAAR,EAAxC,EAAkE,KAAKnC,gBAAvE,CAAP;AACH;;AAC6B,SAAvBgB,uBAAuB,CAAC3G,MAAD,EAASX,UAAT,EAAqB;AAC/C,QAAI2B,GAAG,GAAG,CAAV;AACA,QAAIC,IAAI,GAAGjB,MAAM,CAACvB,MAAP,GAAgB,CAA3B;;AACA,WAAOuC,GAAG,GAAGC,IAAb,EAAmB;AACf,UAAIC,GAAG,GAAGF,GAAG,GAAGG,IAAI,CAACC,KAAL,CAAW,CAACH,IAAI,GAAGD,GAAR,IAAe,CAA1B,CAAhB;;AACA,UAAIhB,MAAM,CAACkB,GAAD,CAAN,CAAY4C,aAAZ,GAA4BzE,UAAhC,EAA4C;AACxC2B,QAAAA,GAAG,GAAGE,GAAG,GAAG,CAAZ;AACH,OAFD,MAGK,IAAIlB,MAAM,CAACkB,GAAD,CAAN,CAAYzB,eAAZ,GAA8BJ,UAAlC,EAA8C;AAC/C4B,QAAAA,IAAI,GAAGC,GAAG,GAAG,CAAb;AACH,OAFI,MAGA;AACD,eAAOA,GAAG,GAAGF,GAAN,IAAahB,MAAM,CAACkB,GAAG,GAAG,CAAP,CAAN,CAAgBzB,eAAhB,IAAmCJ,UAAhD,IAA8DA,UAAU,IAAIW,MAAM,CAACkB,GAAG,GAAG,CAAP,CAAN,CAAgB4C,aAAnG,EAAkH;AAC9G5C,UAAAA,GAAG;AACN;;AACD,eAAOA,GAAP;AACH;AACJ;;AACD,WAAOF,GAAP;AACH,GA5KqB,CA6KtB;;;AACA0D,EAAAA,UAAU,CAACP,KAAD,EAAQhG,QAAR,EAAkBC,eAAlB,EAAmCgF,cAAnC,EAAmDC,aAAnD,EAAkE;AACxE,SAAK,MAAMgD,KAAX,IAAoB,KAAKZ,OAAzB,EAAkC;AAC9BY,MAAAA,KAAK,CAAC3B,UAAN,CAAiBP,KAAjB,EAAwBhG,QAAxB,EAAkCC,eAAlC,EAAmDgF,cAAnD,EAAmEC,aAAnE;AACH;AACJ;;AAlLqB;AAoL1B,OAAO,MAAM0E,WAAN,CAAkB;AACrB7I,EAAAA,WAAW,CAACsG,eAAD,EAAkB;AACzB,SAAKwC,WAAL,GAAmB,EAAnB;AACA,SAAKC,IAAL,GAAY,CAAZ;AACA,SAAKtC,gBAAL,GAAwBH,eAAxB;AACH;;AACDI,EAAAA,KAAK,GAAG;AACJ,SAAKoC,WAAL,GAAmB,EAAnB;AACA,SAAKC,IAAL,GAAY,CAAZ;AACH;;AACDC,EAAAA,SAAS,CAACrJ,kBAAD,EAAqBsG,SAArB,EAAgCgD,QAAhC,EAA0C;AAC/C,QAAIC,aAAa,GAAG,IAApB;;AACA,QAAIjD,SAAS,GAAG,KAAK8C,IAArB,EAA2B;AACvBG,MAAAA,aAAa,GAAG,KAAKJ,WAAL,CAAiB7C,SAAjB,CAAhB;AACH;;AACD,QAAIiD,aAAa,KAAK,IAAlB,IAA0BA,aAAa,KAAKtJ,iBAAhD,EAAmE;AAC/D,aAAO,IAAIjB,UAAJ,CAAewH,aAAa,CAAC+C,aAAD,CAA5B,EAA6CD,QAA7C,EAAuD,KAAKxC,gBAA5D,CAAP;AACH;;AACD,UAAMrG,UAAU,GAAG,IAAIP,WAAJ,CAAgB,CAAhB,CAAnB;AACAO,IAAAA,UAAU,CAAC,CAAD,CAAV,GAAgB6I,QAAQ,CAAC1J,MAAzB;AACAa,IAAAA,UAAU,CAAC,CAAD,CAAV,GAAgBV,kBAAkB,CAAC,KAAK+G,gBAAL,CAAsB0C,gBAAtB,CAAuCxJ,kBAAvC,CAAD,CAAlC;AACA,WAAO,IAAIhB,UAAJ,CAAeyB,UAAf,EAA2B6I,QAA3B,EAAqC,KAAKxC,gBAA1C,CAAP;AACH;;AACoB,SAAd2C,cAAc,CAACzJ,kBAAD,EAAqB0J,cAArB,EAAqC1I,OAArC,EAA8C;AAC/D,UAAMV,MAAM,GAAGU,OAAO,GAAGwF,aAAa,CAACxF,OAAD,CAAhB,GAA4B,IAAlD;;AACA,QAAI0I,cAAc,KAAK,CAAvB,EAA0B;AACtB,UAAIC,sBAAsB,GAAG,KAA7B;;AACA,UAAIrJ,MAAM,IAAIA,MAAM,CAACV,MAAP,GAAgB,CAA9B,EAAiC;AAC7B+J,QAAAA,sBAAsB,GAAIxK,aAAa,CAACyK,aAAd,CAA4BtJ,MAAM,CAAC,CAAD,CAAlC,MAA2CN,kBAArE;AACH;;AACD,UAAI,CAAC2J,sBAAL,EAA6B;AACzB,eAAO1J,iBAAP;AACH;AACJ;;AACD,QAAI,CAACK,MAAD,IAAWA,MAAM,CAACV,MAAP,KAAkB,CAAjC,EAAoC;AAChC,YAAMU,MAAM,GAAG,IAAIJ,WAAJ,CAAgB,CAAhB,CAAf;AACAI,MAAAA,MAAM,CAAC,CAAD,CAAN,GAAYoJ,cAAZ;AACApJ,MAAAA,MAAM,CAAC,CAAD,CAAN,GAAYP,kBAAkB,CAACC,kBAAD,CAA9B;AACA,aAAOM,MAAM,CAACH,MAAd;AACH,KAhB8D,CAiB/D;;;AACAG,IAAAA,MAAM,CAACA,MAAM,CAACV,MAAP,GAAgB,CAAjB,CAAN,GAA4B8J,cAA5B;;AACA,QAAIpJ,MAAM,CAACuJ,UAAP,KAAsB,CAAtB,IAA2BvJ,MAAM,CAACwJ,UAAP,KAAsBxJ,MAAM,CAACH,MAAP,CAAc2J,UAAnE,EAA+E;AAC3E;AACA,aAAOxJ,MAAM,CAACH,MAAd;AACH;;AACD,WAAOG,MAAP;AACH;;AACDyJ,EAAAA,WAAW,CAACzD,SAAD,EAAY;AACnB,WAAOA,SAAS,IAAI,KAAK8C,IAAzB,EAA+B;AAC3B,WAAKD,WAAL,CAAiB,KAAKC,IAAtB,IAA8B,IAA9B;AACA,WAAKA,IAAL;AACH;AACJ;;AACDY,EAAAA,YAAY,CAACC,KAAD,EAAQC,WAAR,EAAqB;AAC7B,QAAIA,WAAW,KAAK,CAApB,EAAuB;AACnB;AACH;;AACD,QAAID,KAAK,GAAGC,WAAR,GAAsB,KAAKd,IAA/B,EAAqC;AACjCc,MAAAA,WAAW,GAAG,KAAKd,IAAL,GAAYa,KAA1B;AACH;;AACD,SAAKd,WAAL,CAAiBzB,MAAjB,CAAwBuC,KAAxB,EAA+BC,WAA/B;;AACA,SAAKd,IAAL,IAAac,WAAb;AACH;;AACDC,EAAAA,YAAY,CAACC,WAAD,EAAcC,WAAd,EAA2B;AACnC,QAAIA,WAAW,KAAK,CAApB,EAAuB;AACnB;AACH;;AACD,QAAI5J,UAAU,GAAG,EAAjB;;AACA,SAAK,IAAIf,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG2K,WAApB,EAAiC3K,CAAC,EAAlC,EAAsC;AAClCe,MAAAA,UAAU,CAACf,CAAD,CAAV,GAAgB,IAAhB;AACH;;AACD,SAAKyJ,WAAL,GAAmBpK,MAAM,CAAC4I,WAAP,CAAmB,KAAKwB,WAAxB,EAAqCiB,WAArC,EAAkD3J,UAAlD,CAAnB;AACA,SAAK2I,IAAL,IAAaiB,WAAb;AACH;;AACDC,EAAAA,SAAS,CAACtK,kBAAD,EAAqBsG,SAArB,EAAgCoD,cAAhC,EAAgD1I,OAAhD,EAAyDuJ,aAAzD,EAAwE;AAC7E,UAAMjK,MAAM,GAAG4I,WAAW,CAACO,cAAZ,CAA2B,KAAK3C,gBAAL,CAAsB0C,gBAAtB,CAAuCxJ,kBAAvC,CAA3B,EAAuF0J,cAAvF,EAAuG1I,OAAvG,CAAf;;AACA,SAAK+I,WAAL,CAAiBzD,SAAjB;;AACA,UAAMkE,SAAS,GAAG,KAAKrB,WAAL,CAAiB7C,SAAjB,CAAlB;AACA,SAAK6C,WAAL,CAAiB7C,SAAjB,IAA8BhG,MAA9B;;AACA,QAAIiK,aAAJ,EAAmB;AACf,aAAO,CAACrB,WAAW,CAACuB,OAAZ,CAAoBD,SAApB,EAA+BlK,MAA/B,CAAR;AACH;;AACD,WAAO,KAAP;AACH;;AACa,SAAPmK,OAAO,CAACC,EAAD,EAAKC,EAAL,EAAS;AACnB,QAAI,CAACD,EAAD,IAAO,CAACC,EAAZ,EAAgB;AACZ,aAAO,CAACD,EAAD,IAAO,CAACC,EAAf;AACH;;AACD,UAAMlF,CAAC,GAAGe,aAAa,CAACkE,EAAD,CAAvB;AACA,UAAMhF,CAAC,GAAGc,aAAa,CAACmE,EAAD,CAAvB;;AACA,QAAIlF,CAAC,CAAC7F,MAAF,KAAa8F,CAAC,CAAC9F,MAAnB,EAA2B;AACvB,aAAO,KAAP;AACH;;AACD,SAAK,IAAIF,CAAC,GAAG,CAAR,EAAWC,GAAG,GAAG8F,CAAC,CAAC7F,MAAxB,EAAgCF,CAAC,GAAGC,GAApC,EAAyCD,CAAC,EAA1C,EAA8C;AAC1C,UAAI+F,CAAC,CAAC/F,CAAD,CAAD,KAASgG,CAAC,CAAChG,CAAD,CAAd,EAAmB;AACf,eAAO,KAAP;AACH;AACJ;;AACD,WAAO,IAAP;AACH,GApGoB,CAqGrB;;;AACAmG,EAAAA,UAAU,CAACP,KAAD,EAAQhG,QAAR,EAAkBC,eAAlB,EAAmC;AACzC,SAAKuG,kBAAL,CAAwBR,KAAxB;;AACA,SAAKS,iBAAL,CAAuB,IAAI9G,QAAJ,CAAaqG,KAAK,CAAC1E,eAAnB,EAAoC0E,KAAK,CAACF,WAA1C,CAAvB,EAA+E9F,QAA/E,EAAyFC,eAAzF;AACH;;AACDuG,EAAAA,kBAAkB,CAACR,KAAD,EAAQ;AACtB,UAAMU,cAAc,GAAGV,KAAK,CAAC1E,eAAN,GAAwB,CAA/C;;AACA,QAAIoF,cAAc,IAAI,KAAKoD,IAA3B,EAAiC;AAC7B;AACH;;AACD,QAAI9D,KAAK,CAAC1E,eAAN,KAA0B0E,KAAK,CAACL,aAApC,EAAmD;AAC/C,UAAIK,KAAK,CAACF,WAAN,KAAsBE,KAAK,CAACD,SAAhC,EAA2C;AACvC;AACA;AACH;;AACD,WAAK8D,WAAL,CAAiBnD,cAAjB,IAAmCkD,WAAW,CAAC0B,OAAZ,CAAoB,KAAKzB,WAAL,CAAiBnD,cAAjB,CAApB,EAAsDV,KAAK,CAACF,WAAN,GAAoB,CAA1E,EAA6EE,KAAK,CAACD,SAAN,GAAkB,CAA/F,CAAnC;AACA;AACH;;AACD,SAAK8D,WAAL,CAAiBnD,cAAjB,IAAmCkD,WAAW,CAAC2B,aAAZ,CAA0B,KAAK1B,WAAL,CAAiBnD,cAAjB,CAA1B,EAA4DV,KAAK,CAACF,WAAN,GAAoB,CAAhF,CAAnC;AACA,UAAMa,aAAa,GAAGX,KAAK,CAACL,aAAN,GAAsB,CAA5C;AACA,QAAI6F,cAAc,GAAG,IAArB;;AACA,QAAI7E,aAAa,GAAG,KAAKmD,IAAzB,EAA+B;AAC3B0B,MAAAA,cAAc,GAAG5B,WAAW,CAAC6B,gBAAZ,CAA6B,KAAK5B,WAAL,CAAiBlD,aAAjB,CAA7B,EAA8DX,KAAK,CAACD,SAAN,GAAkB,CAAhF,CAAjB;AACH,KAlBqB,CAmBtB;;;AACA,SAAK8D,WAAL,CAAiBnD,cAAjB,IAAmCkD,WAAW,CAAC8B,OAAZ,CAAoB,KAAK7B,WAAL,CAAiBnD,cAAjB,CAApB,EAAsD8E,cAAtD,CAAnC,CApBsB,CAqBtB;;AACA,SAAKd,YAAL,CAAkB1E,KAAK,CAAC1E,eAAxB,EAAyC0E,KAAK,CAACL,aAAN,GAAsBK,KAAK,CAAC1E,eAArE;AACH;;AACDmF,EAAAA,iBAAiB,CAACM,QAAD,EAAW/G,QAAX,EAAqBC,eAArB,EAAsC;AACnD,QAAID,QAAQ,KAAK,CAAb,IAAkBC,eAAe,KAAK,CAA1C,EAA6C;AACzC;AACA;AACH;;AACD,UAAM+G,SAAS,GAAGD,QAAQ,CAAC7F,UAAT,GAAsB,CAAxC;;AACA,QAAI8F,SAAS,IAAI,KAAK8C,IAAtB,EAA4B;AACxB;AACH;;AACD,QAAI9J,QAAQ,KAAK,CAAjB,EAAoB;AAChB;AACA,WAAK6J,WAAL,CAAiB7C,SAAjB,IAA8B4C,WAAW,CAAC+B,OAAZ,CAAoB,KAAK9B,WAAL,CAAiB7C,SAAjB,CAApB,EAAiDD,QAAQ,CAACE,MAAT,GAAkB,CAAnE,EAAsEhH,eAAtE,CAA9B;AACA;AACH;;AACD,SAAK4J,WAAL,CAAiB7C,SAAjB,IAA8B4C,WAAW,CAAC2B,aAAZ,CAA0B,KAAK1B,WAAL,CAAiB7C,SAAjB,CAA1B,EAAuDD,QAAQ,CAACE,MAAT,GAAkB,CAAzE,CAA9B;AACA,SAAK4C,WAAL,CAAiB7C,SAAjB,IAA8B4C,WAAW,CAAC+B,OAAZ,CAAoB,KAAK9B,WAAL,CAAiB7C,SAAjB,CAApB,EAAiDD,QAAQ,CAACE,MAAT,GAAkB,CAAnE,EAAsEhH,eAAtE,CAA9B;;AACA,SAAK4K,YAAL,CAAkB9D,QAAQ,CAAC7F,UAA3B,EAAuClB,QAAvC;AACH;;AACsB,SAAhByL,gBAAgB,CAACtK,UAAD,EAAayK,SAAb,EAAwB;AAC3C,QAAIzK,UAAU,KAAK,IAAf,IAAuBA,UAAU,KAAKR,iBAA1C,EAA6D;AACzD,aAAOQ,UAAP;AACH;;AACD,WAAOyI,WAAW,CAAC0B,OAAZ,CAAoBnK,UAApB,EAAgC,CAAhC,EAAmCyK,SAAnC,CAAP;AACH;;AACmB,SAAbL,aAAa,CAACpK,UAAD,EAAa0K,WAAb,EAA0B;AAC1C,QAAI1K,UAAU,KAAK,IAAf,IAAuBA,UAAU,KAAKR,iBAA1C,EAA6D;AACzD,aAAOQ,UAAP;AACH;;AACD,UAAMH,MAAM,GAAGkG,aAAa,CAAC/F,UAAD,CAA5B;AACA,UAAMiJ,cAAc,GAAGpJ,MAAM,CAACA,MAAM,CAACV,MAAP,GAAgB,CAAjB,CAA7B;AACA,WAAOsJ,WAAW,CAAC0B,OAAZ,CAAoBnK,UAApB,EAAgC0K,WAAhC,EAA6CzB,cAA7C,CAAP;AACH;;AACa,SAAPkB,OAAO,CAACnK,UAAD,EAAa0K,WAAb,EAA0BD,SAA1B,EAAqC;AAC/C,QAAIzK,UAAU,KAAK,IAAf,IAAuBA,UAAU,KAAKR,iBAAtC,IAA2DkL,WAAW,KAAKD,SAA/E,EAA0F;AACtF,aAAOzK,UAAP;AACH;;AACD,UAAMH,MAAM,GAAGkG,aAAa,CAAC/F,UAAD,CAA5B;AACA,UAAM2K,WAAW,GAAI9K,MAAM,CAACV,MAAP,KAAkB,CAAvC,CAL+C,CAM/C;;AACA,QAAIuL,WAAW,KAAK,CAAhB,IAAqB7K,MAAM,CAACA,MAAM,CAACV,MAAP,GAAgB,CAAjB,CAAN,KAA8BsL,SAAvD,EAAkE;AAC9D,aAAOjL,iBAAP;AACH;;AACD,UAAMoL,cAAc,GAAGrM,UAAU,CAACsM,sBAAX,CAAkChL,MAAlC,EAA0C6K,WAA1C,CAAvB;AACA,UAAMI,oBAAoB,GAAIF,cAAc,GAAG,CAAjB,GAAqB/K,MAAM,CAAE+K,cAAc,GAAG,CAAlB,IAAwB,CAAzB,CAA3B,GAAyD,CAAvF;AACA,UAAMG,kBAAkB,GAAGlL,MAAM,CAAC+K,cAAc,IAAI,CAAnB,CAAjC;;AACA,QAAIH,SAAS,GAAGM,kBAAhB,EAAoC;AAChC;AACA,YAAMC,KAAK,GAAIP,SAAS,GAAGC,WAA3B;;AACA,WAAK,IAAIzL,CAAC,GAAG2L,cAAb,EAA6B3L,CAAC,GAAG0L,WAAjC,EAA8C1L,CAAC,EAA/C,EAAmD;AAC/CY,QAAAA,MAAM,CAACZ,CAAC,IAAI,CAAN,CAAN,IAAkB+L,KAAlB;AACH;;AACD,aAAOhL,UAAP;AACH;;AACD,QAAIiL,IAAJ;AACA,QAAIC,OAAJ;;AACA,QAAIJ,oBAAoB,KAAKJ,WAA7B,EAA0C;AACtC7K,MAAAA,MAAM,CAAC+K,cAAc,IAAI,CAAnB,CAAN,GAA8BF,WAA9B;AACAO,MAAAA,IAAI,GAAKL,cAAc,GAAG,CAAlB,IAAwB,CAAhC;AACAM,MAAAA,OAAO,GAAGR,WAAV;AACH,KAJD,MAKK;AACDO,MAAAA,IAAI,GAAIL,cAAc,IAAI,CAA1B;AACAM,MAAAA,OAAO,GAAGJ,oBAAV;AACH;;AACD,UAAME,KAAK,GAAIP,SAAS,GAAGC,WAA3B;;AACA,SAAK,IAAIpJ,UAAU,GAAGsJ,cAAc,GAAG,CAAvC,EAA0CtJ,UAAU,GAAGqJ,WAAvD,EAAoErJ,UAAU,EAA9E,EAAkF;AAC9E,YAAM6J,cAAc,GAAGtL,MAAM,CAACyB,UAAU,IAAI,CAAf,CAAN,GAA0B0J,KAAjD;;AACA,UAAIG,cAAc,GAAGD,OAArB,EAA8B;AAC1BrL,QAAAA,MAAM,CAACoL,IAAI,EAAL,CAAN,GAAiBE,cAAjB;AACAtL,QAAAA,MAAM,CAACoL,IAAI,EAAL,CAAN,GAAiBpL,MAAM,CAAC,CAACyB,UAAU,IAAI,CAAf,IAAoB,CAArB,CAAvB;AACA4J,QAAAA,OAAO,GAAGC,cAAV;AACH;AACJ;;AACD,QAAIF,IAAI,KAAKpL,MAAM,CAACV,MAApB,EAA4B;AACxB;AACA,aAAOa,UAAP;AACH;;AACD,QAAIoL,GAAG,GAAG,IAAI3L,WAAJ,CAAgBwL,IAAhB,CAAV;AACAG,IAAAA,GAAG,CAAC7E,GAAJ,CAAQ1G,MAAM,CAACsC,QAAP,CAAgB,CAAhB,EAAmB8I,IAAnB,CAAR,EAAkC,CAAlC;AACA,WAAOG,GAAG,CAAC1L,MAAX;AACH;;AACa,SAAP6K,OAAO,CAACvK,UAAD,EAAaqL,YAAb,EAA2B;AACrC,QAAIA,YAAY,KAAK7L,iBAArB,EAAwC;AACpC,aAAOQ,UAAP;AACH;;AACD,QAAIA,UAAU,KAAKR,iBAAnB,EAAsC;AAClC,aAAO6L,YAAP;AACH;;AACD,QAAIrL,UAAU,KAAK,IAAnB,EAAyB;AACrB,aAAOA,UAAP;AACH;;AACD,QAAIqL,YAAY,KAAK,IAArB,EAA2B;AACvB;AACA,aAAO,IAAP;AACH;;AACD,UAAMC,QAAQ,GAAGvF,aAAa,CAAC/F,UAAD,CAA9B;AACA,UAAMuL,WAAW,GAAGxF,aAAa,CAACsF,YAAD,CAAjC;AACA,UAAMG,gBAAgB,GAAID,WAAW,CAACpM,MAAZ,KAAuB,CAAjD;AACA,QAAIsI,MAAM,GAAG,IAAIhI,WAAJ,CAAgB6L,QAAQ,CAACnM,MAAT,GAAkBoM,WAAW,CAACpM,MAA9C,CAAb;AACAsI,IAAAA,MAAM,CAAClB,GAAP,CAAW+E,QAAX,EAAqB,CAArB;AACA,QAAIL,IAAI,GAAGK,QAAQ,CAACnM,MAApB;AACA,UAAM6L,KAAK,GAAGM,QAAQ,CAACA,QAAQ,CAACnM,MAAT,GAAkB,CAAnB,CAAtB;;AACA,SAAK,IAAIF,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGuM,gBAApB,EAAsCvM,CAAC,EAAvC,EAA2C;AACvCwI,MAAAA,MAAM,CAACwD,IAAI,EAAL,CAAN,GAAiBM,WAAW,CAAEtM,CAAC,IAAI,CAAP,CAAX,GAAwB+L,KAAzC;AACAvD,MAAAA,MAAM,CAACwD,IAAI,EAAL,CAAN,GAAiBM,WAAW,CAAC,CAACtM,CAAC,IAAI,CAAN,IAAW,CAAZ,CAA5B;AACH;;AACD,WAAOwI,MAAM,CAAC/H,MAAd;AACH;;AACa,SAAP8K,OAAO,CAACxK,UAAD,EAAayL,OAAb,EAAsBC,UAAtB,EAAkC;AAC5C,QAAI1L,UAAU,KAAK,IAAf,IAAuBA,UAAU,KAAKR,iBAA1C,EAA6D;AACzD;AACA,aAAOQ,UAAP;AACH;;AACD,UAAMH,MAAM,GAAGkG,aAAa,CAAC/F,UAAD,CAA5B;AACA,UAAM2K,WAAW,GAAI9K,MAAM,CAACV,MAAP,KAAkB,CAAvC;AACA,QAAIyL,cAAc,GAAGrM,UAAU,CAACsM,sBAAX,CAAkChL,MAAlC,EAA0C4L,OAA1C,CAArB;;AACA,QAAIb,cAAc,GAAG,CAArB,EAAwB;AACpB,YAAME,oBAAoB,GAAGjL,MAAM,CAAE+K,cAAc,GAAG,CAAlB,IAAwB,CAAzB,CAAnC;;AACA,UAAIE,oBAAoB,KAAKW,OAA7B,EAAsC;AAClCb,QAAAA,cAAc;AACjB;AACJ;;AACD,SAAK,IAAItJ,UAAU,GAAGsJ,cAAtB,EAAsCtJ,UAAU,GAAGqJ,WAAnD,EAAgErJ,UAAU,EAA1E,EAA8E;AAC1EzB,MAAAA,MAAM,CAACyB,UAAU,IAAI,CAAf,CAAN,IAA2BoK,UAA3B;AACH;;AACD,WAAO1L,UAAP;AACH;;AAhQoB","sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport * as arrays from '../../../base/common/arrays.js';\nimport { LineTokens } from '../core/lineTokens.js';\nimport { Position } from '../core/position.js';\nimport { Range } from '../core/range.js';\nimport { TokenMetadata } from '../modes.js';\nexport function countEOL(text) {\n    let eolCount = 0;\n    let firstLineLength = 0;\n    let lastLineStart = 0;\n    let eol = 0 /* Unknown */;\n    for (let i = 0, len = text.length; i < len; i++) {\n        const chr = text.charCodeAt(i);\n        if (chr === 13 /* CarriageReturn */) {\n            if (eolCount === 0) {\n                firstLineLength = i;\n            }\n            eolCount++;\n            if (i + 1 < len && text.charCodeAt(i + 1) === 10 /* LineFeed */) {\n                // \\r\\n... case\n                eol |= 2 /* CRLF */;\n                i++; // skip \\n\n            }\n            else {\n                // \\r... case\n                eol |= 3 /* Invalid */;\n            }\n            lastLineStart = i + 1;\n        }\n        else if (chr === 10 /* LineFeed */) {\n            // \\n... case\n            eol |= 1 /* LF */;\n            if (eolCount === 0) {\n                firstLineLength = i;\n            }\n            eolCount++;\n            lastLineStart = i + 1;\n        }\n    }\n    if (eolCount === 0) {\n        firstLineLength = text.length;\n    }\n    return [eolCount, firstLineLength, text.length - lastLineStart, eol];\n}\nfunction getDefaultMetadata(topLevelLanguageId) {\n    return ((topLevelLanguageId << 0 /* LANGUAGEID_OFFSET */)\n        | (0 /* Other */ << 8 /* TOKEN_TYPE_OFFSET */)\n        | (0 /* None */ << 11 /* FONT_STYLE_OFFSET */)\n        | (1 /* DefaultForeground */ << 14 /* FOREGROUND_OFFSET */)\n        | (2 /* DefaultBackground */ << 23 /* BACKGROUND_OFFSET */)) >>> 0;\n}\nconst EMPTY_LINE_TOKENS = (new Uint32Array(0)).buffer;\nexport class MultilineTokensBuilder {\n    constructor() {\n        this.tokens = [];\n    }\n    add(lineNumber, lineTokens) {\n        if (this.tokens.length > 0) {\n            const last = this.tokens[this.tokens.length - 1];\n            const lastLineNumber = last.startLineNumber + last.tokens.length - 1;\n            if (lastLineNumber + 1 === lineNumber) {\n                // append\n                last.tokens.push(lineTokens);\n                return;\n            }\n        }\n        this.tokens.push(new MultilineTokens(lineNumber, [lineTokens]));\n    }\n}\nexport class SparseEncodedTokens {\n    constructor(tokens) {\n        this._tokens = tokens;\n        this._tokenCount = tokens.length / 4;\n    }\n    toString(startLineNumber) {\n        let pieces = [];\n        for (let i = 0; i < this._tokenCount; i++) {\n            pieces.push(`(${this._getDeltaLine(i) + startLineNumber},${this._getStartCharacter(i)}-${this._getEndCharacter(i)})`);\n        }\n        return `[${pieces.join(',')}]`;\n    }\n    getMaxDeltaLine() {\n        const tokenCount = this._getTokenCount();\n        if (tokenCount === 0) {\n            return -1;\n        }\n        return this._getDeltaLine(tokenCount - 1);\n    }\n    getRange() {\n        const tokenCount = this._getTokenCount();\n        if (tokenCount === 0) {\n            return null;\n        }\n        const startChar = this._getStartCharacter(0);\n        const maxDeltaLine = this._getDeltaLine(tokenCount - 1);\n        const endChar = this._getEndCharacter(tokenCount - 1);\n        return new Range(0, startChar + 1, maxDeltaLine, endChar + 1);\n    }\n    _getTokenCount() {\n        return this._tokenCount;\n    }\n    _getDeltaLine(tokenIndex) {\n        return this._tokens[4 * tokenIndex];\n    }\n    _getStartCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 1];\n    }\n    _getEndCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 2];\n    }\n    isEmpty() {\n        return (this._getTokenCount() === 0);\n    }\n    getLineTokens(deltaLine) {\n        let low = 0;\n        let high = this._getTokenCount() - 1;\n        while (low < high) {\n            const mid = low + Math.floor((high - low) / 2);\n            const midDeltaLine = this._getDeltaLine(mid);\n            if (midDeltaLine < deltaLine) {\n                low = mid + 1;\n            }\n            else if (midDeltaLine > deltaLine) {\n                high = mid - 1;\n            }\n            else {\n                let min = mid;\n                while (min > low && this._getDeltaLine(min - 1) === deltaLine) {\n                    min--;\n                }\n                let max = mid;\n                while (max < high && this._getDeltaLine(max + 1) === deltaLine) {\n                    max++;\n                }\n                return new LineTokens2(this._tokens.subarray(4 * min, 4 * max + 4));\n            }\n        }\n        if (this._getDeltaLine(low) === deltaLine) {\n            return new LineTokens2(this._tokens.subarray(4 * low, 4 * low + 4));\n        }\n        return null;\n    }\n    clear() {\n        this._tokenCount = 0;\n    }\n    removeTokens(startDeltaLine, startChar, endDeltaLine, endChar) {\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        let newTokenCount = 0;\n        let hasDeletedTokens = false;\n        let firstDeltaLine = 0;\n        for (let i = 0; i < tokenCount; i++) {\n            const srcOffset = 4 * i;\n            const tokenDeltaLine = tokens[srcOffset];\n            const tokenStartCharacter = tokens[srcOffset + 1];\n            const tokenEndCharacter = tokens[srcOffset + 2];\n            const tokenMetadata = tokens[srcOffset + 3];\n            if ((tokenDeltaLine > startDeltaLine || (tokenDeltaLine === startDeltaLine && tokenEndCharacter >= startChar))\n                && (tokenDeltaLine < endDeltaLine || (tokenDeltaLine === endDeltaLine && tokenStartCharacter <= endChar))) {\n                hasDeletedTokens = true;\n            }\n            else {\n                if (newTokenCount === 0) {\n                    firstDeltaLine = tokenDeltaLine;\n                }\n                if (hasDeletedTokens) {\n                    // must move the token to the left\n                    const destOffset = 4 * newTokenCount;\n                    tokens[destOffset] = tokenDeltaLine - firstDeltaLine;\n                    tokens[destOffset + 1] = tokenStartCharacter;\n                    tokens[destOffset + 2] = tokenEndCharacter;\n                    tokens[destOffset + 3] = tokenMetadata;\n                }\n                newTokenCount++;\n            }\n        }\n        this._tokenCount = newTokenCount;\n        return firstDeltaLine;\n    }\n    split(startDeltaLine, startChar, endDeltaLine, endChar) {\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        let aTokens = [];\n        let bTokens = [];\n        let destTokens = aTokens;\n        let destOffset = 0;\n        let destFirstDeltaLine = 0;\n        for (let i = 0; i < tokenCount; i++) {\n            const srcOffset = 4 * i;\n            const tokenDeltaLine = tokens[srcOffset];\n            const tokenStartCharacter = tokens[srcOffset + 1];\n            const tokenEndCharacter = tokens[srcOffset + 2];\n            const tokenMetadata = tokens[srcOffset + 3];\n            if ((tokenDeltaLine > startDeltaLine || (tokenDeltaLine === startDeltaLine && tokenEndCharacter >= startChar))) {\n                if ((tokenDeltaLine < endDeltaLine || (tokenDeltaLine === endDeltaLine && tokenStartCharacter <= endChar))) {\n                    // this token is touching the range\n                    continue;\n                }\n                else {\n                    // this token is after the range\n                    if (destTokens !== bTokens) {\n                        // this token is the first token after the range\n                        destTokens = bTokens;\n                        destOffset = 0;\n                        destFirstDeltaLine = tokenDeltaLine;\n                    }\n                }\n            }\n            destTokens[destOffset++] = tokenDeltaLine - destFirstDeltaLine;\n            destTokens[destOffset++] = tokenStartCharacter;\n            destTokens[destOffset++] = tokenEndCharacter;\n            destTokens[destOffset++] = tokenMetadata;\n        }\n        return [new SparseEncodedTokens(new Uint32Array(aTokens)), new SparseEncodedTokens(new Uint32Array(bTokens)), destFirstDeltaLine];\n    }\n    acceptDeleteRange(horizontalShiftForFirstLineTokens, startDeltaLine, startCharacter, endDeltaLine, endCharacter) {\n        // This is a bit complex, here are the cases I used to think about this:\n        //\n        // 1. The token starts before the deletion range\n        // 1a. The token is completely before the deletion range\n        //               -----------\n        //                          xxxxxxxxxxx\n        // 1b. The token starts before, the deletion range ends after the token\n        //               -----------\n        //                      xxxxxxxxxxx\n        // 1c. The token starts before, the deletion range ends precisely with the token\n        //               ---------------\n        //                      xxxxxxxx\n        // 1d. The token starts before, the deletion range is inside the token\n        //               ---------------\n        //                    xxxxx\n        //\n        // 2. The token starts at the same position with the deletion range\n        // 2a. The token starts at the same position, and ends inside the deletion range\n        //               -------\n        //               xxxxxxxxxxx\n        // 2b. The token starts at the same position, and ends at the same position as the deletion range\n        //               ----------\n        //               xxxxxxxxxx\n        // 2c. The token starts at the same position, and ends after the deletion range\n        //               -------------\n        //               xxxxxxx\n        //\n        // 3. The token starts inside the deletion range\n        // 3a. The token is inside the deletion range\n        //                -------\n        //             xxxxxxxxxxxxx\n        // 3b. The token starts inside the deletion range, and ends at the same position as the deletion range\n        //                ----------\n        //             xxxxxxxxxxxxx\n        // 3c. The token starts inside the deletion range, and ends after the deletion range\n        //                ------------\n        //             xxxxxxxxxxx\n        //\n        // 4. The token starts after the deletion range\n        //                  -----------\n        //          xxxxxxxx\n        //\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        const deletedLineCount = (endDeltaLine - startDeltaLine);\n        let newTokenCount = 0;\n        let hasDeletedTokens = false;\n        for (let i = 0; i < tokenCount; i++) {\n            const srcOffset = 4 * i;\n            let tokenDeltaLine = tokens[srcOffset];\n            let tokenStartCharacter = tokens[srcOffset + 1];\n            let tokenEndCharacter = tokens[srcOffset + 2];\n            const tokenMetadata = tokens[srcOffset + 3];\n            if (tokenDeltaLine < startDeltaLine || (tokenDeltaLine === startDeltaLine && tokenEndCharacter <= startCharacter)) {\n                // 1a. The token is completely before the deletion range\n                // => nothing to do\n                newTokenCount++;\n                continue;\n            }\n            else if (tokenDeltaLine === startDeltaLine && tokenStartCharacter < startCharacter) {\n                // 1b, 1c, 1d\n                // => the token survives, but it needs to shrink\n                if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n                    // 1d. The token starts before, the deletion range is inside the token\n                    // => the token shrinks by the deletion character count\n                    tokenEndCharacter -= (endCharacter - startCharacter);\n                }\n                else {\n                    // 1b. The token starts before, the deletion range ends after the token\n                    // 1c. The token starts before, the deletion range ends precisely with the token\n                    // => the token shrinks its ending to the deletion start\n                    tokenEndCharacter = startCharacter;\n                }\n            }\n            else if (tokenDeltaLine === startDeltaLine && tokenStartCharacter === startCharacter) {\n                // 2a, 2b, 2c\n                if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n                    // 2c. The token starts at the same position, and ends after the deletion range\n                    // => the token shrinks by the deletion character count\n                    tokenEndCharacter -= (endCharacter - startCharacter);\n                }\n                else {\n                    // 2a. The token starts at the same position, and ends inside the deletion range\n                    // 2b. The token starts at the same position, and ends at the same position as the deletion range\n                    // => the token is deleted\n                    hasDeletedTokens = true;\n                    continue;\n                }\n            }\n            else if (tokenDeltaLine < endDeltaLine || (tokenDeltaLine === endDeltaLine && tokenStartCharacter < endCharacter)) {\n                // 3a, 3b, 3c\n                if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n                    // 3c. The token starts inside the deletion range, and ends after the deletion range\n                    // => the token moves left and shrinks\n                    if (tokenDeltaLine === startDeltaLine) {\n                        // the deletion started on the same line as the token\n                        // => the token moves left and shrinks\n                        tokenStartCharacter = startCharacter;\n                        tokenEndCharacter = tokenStartCharacter + (tokenEndCharacter - endCharacter);\n                    }\n                    else {\n                        // the deletion started on a line above the token\n                        // => the token moves to the beginning of the line\n                        tokenStartCharacter = 0;\n                        tokenEndCharacter = tokenStartCharacter + (tokenEndCharacter - endCharacter);\n                    }\n                }\n                else {\n                    // 3a. The token is inside the deletion range\n                    // 3b. The token starts inside the deletion range, and ends at the same position as the deletion range\n                    // => the token is deleted\n                    hasDeletedTokens = true;\n                    continue;\n                }\n            }\n            else if (tokenDeltaLine > endDeltaLine) {\n                // 4. (partial) The token starts after the deletion range, on a line below...\n                if (deletedLineCount === 0 && !hasDeletedTokens) {\n                    // early stop, there is no need to walk all the tokens and do nothing...\n                    newTokenCount = tokenCount;\n                    break;\n                }\n                tokenDeltaLine -= deletedLineCount;\n            }\n            else if (tokenDeltaLine === endDeltaLine && tokenStartCharacter >= endCharacter) {\n                // 4. (continued) The token starts after the deletion range, on the last line where a deletion occurs\n                if (horizontalShiftForFirstLineTokens && tokenDeltaLine === 0) {\n                    tokenStartCharacter += horizontalShiftForFirstLineTokens;\n                    tokenEndCharacter += horizontalShiftForFirstLineTokens;\n                }\n                tokenDeltaLine -= deletedLineCount;\n                tokenStartCharacter -= (endCharacter - startCharacter);\n                tokenEndCharacter -= (endCharacter - startCharacter);\n            }\n            else {\n                throw new Error(`Not possible!`);\n            }\n            const destOffset = 4 * newTokenCount;\n            tokens[destOffset] = tokenDeltaLine;\n            tokens[destOffset + 1] = tokenStartCharacter;\n            tokens[destOffset + 2] = tokenEndCharacter;\n            tokens[destOffset + 3] = tokenMetadata;\n            newTokenCount++;\n        }\n        this._tokenCount = newTokenCount;\n    }\n    acceptInsertText(deltaLine, character, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n        // Here are the cases I used to think about this:\n        //\n        // 1. The token is completely before the insertion point\n        //            -----------   |\n        // 2. The token ends precisely at the insertion point\n        //            -----------|\n        // 3. The token contains the insertion point\n        //            -----|------\n        // 4. The token starts precisely at the insertion point\n        //            |-----------\n        // 5. The token is completely after the insertion point\n        //            |   -----------\n        //\n        const isInsertingPreciselyOneWordCharacter = (eolCount === 0\n            && firstLineLength === 1\n            && ((firstCharCode >= 48 /* Digit0 */ && firstCharCode <= 57 /* Digit9 */)\n                || (firstCharCode >= 65 /* A */ && firstCharCode <= 90 /* Z */)\n                || (firstCharCode >= 97 /* a */ && firstCharCode <= 122 /* z */)));\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        for (let i = 0; i < tokenCount; i++) {\n            const offset = 4 * i;\n            let tokenDeltaLine = tokens[offset];\n            let tokenStartCharacter = tokens[offset + 1];\n            let tokenEndCharacter = tokens[offset + 2];\n            if (tokenDeltaLine < deltaLine || (tokenDeltaLine === deltaLine && tokenEndCharacter < character)) {\n                // 1. The token is completely before the insertion point\n                // => nothing to do\n                continue;\n            }\n            else if (tokenDeltaLine === deltaLine && tokenEndCharacter === character) {\n                // 2. The token ends precisely at the insertion point\n                // => expand the end character only if inserting precisely one character that is a word character\n                if (isInsertingPreciselyOneWordCharacter) {\n                    tokenEndCharacter += 1;\n                }\n                else {\n                    continue;\n                }\n            }\n            else if (tokenDeltaLine === deltaLine && tokenStartCharacter < character && character < tokenEndCharacter) {\n                // 3. The token contains the insertion point\n                if (eolCount === 0) {\n                    // => just expand the end character\n                    tokenEndCharacter += firstLineLength;\n                }\n                else {\n                    // => cut off the token\n                    tokenEndCharacter = character;\n                }\n            }\n            else {\n                // 4. or 5.\n                if (tokenDeltaLine === deltaLine && tokenStartCharacter === character) {\n                    // 4. The token starts precisely at the insertion point\n                    // => grow the token (by keeping its start constant) only if inserting precisely one character that is a word character\n                    // => otherwise behave as in case 5.\n                    if (isInsertingPreciselyOneWordCharacter) {\n                        continue;\n                    }\n                }\n                // => the token must move and keep its size constant\n                if (tokenDeltaLine === deltaLine) {\n                    tokenDeltaLine += eolCount;\n                    // this token is on the line where the insertion is taking place\n                    if (eolCount === 0) {\n                        tokenStartCharacter += firstLineLength;\n                        tokenEndCharacter += firstLineLength;\n                    }\n                    else {\n                        const tokenLength = tokenEndCharacter - tokenStartCharacter;\n                        tokenStartCharacter = lastLineLength + (tokenStartCharacter - character);\n                        tokenEndCharacter = tokenStartCharacter + tokenLength;\n                    }\n                }\n                else {\n                    tokenDeltaLine += eolCount;\n                }\n            }\n            tokens[offset] = tokenDeltaLine;\n            tokens[offset + 1] = tokenStartCharacter;\n            tokens[offset + 2] = tokenEndCharacter;\n        }\n    }\n}\nexport class LineTokens2 {\n    constructor(tokens) {\n        this._tokens = tokens;\n    }\n    getCount() {\n        return this._tokens.length / 4;\n    }\n    getStartCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 1];\n    }\n    getEndCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 2];\n    }\n    getMetadata(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 3];\n    }\n}\nexport class MultilineTokens2 {\n    constructor(startLineNumber, tokens) {\n        this.startLineNumber = startLineNumber;\n        this.tokens = tokens;\n        this.endLineNumber = this.startLineNumber + this.tokens.getMaxDeltaLine();\n    }\n    toString() {\n        return this.tokens.toString(this.startLineNumber);\n    }\n    _updateEndLineNumber() {\n        this.endLineNumber = this.startLineNumber + this.tokens.getMaxDeltaLine();\n    }\n    isEmpty() {\n        return this.tokens.isEmpty();\n    }\n    getLineTokens(lineNumber) {\n        if (this.startLineNumber <= lineNumber && lineNumber <= this.endLineNumber) {\n            return this.tokens.getLineTokens(lineNumber - this.startLineNumber);\n        }\n        return null;\n    }\n    getRange() {\n        const deltaRange = this.tokens.getRange();\n        if (!deltaRange) {\n            return deltaRange;\n        }\n        return new Range(this.startLineNumber + deltaRange.startLineNumber, deltaRange.startColumn, this.startLineNumber + deltaRange.endLineNumber, deltaRange.endColumn);\n    }\n    removeTokens(range) {\n        const startLineIndex = range.startLineNumber - this.startLineNumber;\n        const endLineIndex = range.endLineNumber - this.startLineNumber;\n        this.startLineNumber += this.tokens.removeTokens(startLineIndex, range.startColumn - 1, endLineIndex, range.endColumn - 1);\n        this._updateEndLineNumber();\n    }\n    split(range) {\n        // split tokens to two:\n        // a) all the tokens before `range`\n        // b) all the tokens after `range`\n        const startLineIndex = range.startLineNumber - this.startLineNumber;\n        const endLineIndex = range.endLineNumber - this.startLineNumber;\n        const [a, b, bDeltaLine] = this.tokens.split(startLineIndex, range.startColumn - 1, endLineIndex, range.endColumn - 1);\n        return [new MultilineTokens2(this.startLineNumber, a), new MultilineTokens2(this.startLineNumber + bDeltaLine, b)];\n    }\n    applyEdit(range, text) {\n        const [eolCount, firstLineLength, lastLineLength] = countEOL(text);\n        this.acceptEdit(range, eolCount, firstLineLength, lastLineLength, text.length > 0 ? text.charCodeAt(0) : 0 /* Null */);\n    }\n    acceptEdit(range, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n        this._acceptDeleteRange(range);\n        this._acceptInsertText(new Position(range.startLineNumber, range.startColumn), eolCount, firstLineLength, lastLineLength, firstCharCode);\n        this._updateEndLineNumber();\n    }\n    _acceptDeleteRange(range) {\n        if (range.startLineNumber === range.endLineNumber && range.startColumn === range.endColumn) {\n            // Nothing to delete\n            return;\n        }\n        const firstLineIndex = range.startLineNumber - this.startLineNumber;\n        const lastLineIndex = range.endLineNumber - this.startLineNumber;\n        if (lastLineIndex < 0) {\n            // this deletion occurs entirely before this block, so we only need to adjust line numbers\n            const deletedLinesCount = lastLineIndex - firstLineIndex;\n            this.startLineNumber -= deletedLinesCount;\n            return;\n        }\n        const tokenMaxDeltaLine = this.tokens.getMaxDeltaLine();\n        if (firstLineIndex >= tokenMaxDeltaLine + 1) {\n            // this deletion occurs entirely after this block, so there is nothing to do\n            return;\n        }\n        if (firstLineIndex < 0 && lastLineIndex >= tokenMaxDeltaLine + 1) {\n            // this deletion completely encompasses this block\n            this.startLineNumber = 0;\n            this.tokens.clear();\n            return;\n        }\n        if (firstLineIndex < 0) {\n            const deletedBefore = -firstLineIndex;\n            this.startLineNumber -= deletedBefore;\n            this.tokens.acceptDeleteRange(range.startColumn - 1, 0, 0, lastLineIndex, range.endColumn - 1);\n        }\n        else {\n            this.tokens.acceptDeleteRange(0, firstLineIndex, range.startColumn - 1, lastLineIndex, range.endColumn - 1);\n        }\n    }\n    _acceptInsertText(position, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n        if (eolCount === 0 && firstLineLength === 0) {\n            // Nothing to insert\n            return;\n        }\n        const lineIndex = position.lineNumber - this.startLineNumber;\n        if (lineIndex < 0) {\n            // this insertion occurs before this block, so we only need to adjust line numbers\n            this.startLineNumber += eolCount;\n            return;\n        }\n        const tokenMaxDeltaLine = this.tokens.getMaxDeltaLine();\n        if (lineIndex >= tokenMaxDeltaLine + 1) {\n            // this insertion occurs after this block, so there is nothing to do\n            return;\n        }\n        this.tokens.acceptInsertText(lineIndex, position.column - 1, eolCount, firstLineLength, lastLineLength, firstCharCode);\n    }\n}\nexport class MultilineTokens {\n    constructor(startLineNumber, tokens) {\n        this.startLineNumber = startLineNumber;\n        this.tokens = tokens;\n    }\n}\nfunction toUint32Array(arr) {\n    if (arr instanceof Uint32Array) {\n        return arr;\n    }\n    else {\n        return new Uint32Array(arr);\n    }\n}\nexport class TokensStore2 {\n    constructor(languageIdCodec) {\n        this._pieces = [];\n        this._isComplete = false;\n        this._languageIdCodec = languageIdCodec;\n    }\n    flush() {\n        this._pieces = [];\n        this._isComplete = false;\n    }\n    isEmpty() {\n        return (this._pieces.length === 0);\n    }\n    set(pieces, isComplete) {\n        this._pieces = pieces || [];\n        this._isComplete = isComplete;\n    }\n    setPartial(_range, pieces) {\n        // console.log(`setPartial ${_range} ${pieces.map(p => p.toString()).join(', ')}`);\n        let range = _range;\n        if (pieces.length > 0) {\n            const _firstRange = pieces[0].getRange();\n            const _lastRange = pieces[pieces.length - 1].getRange();\n            if (!_firstRange || !_lastRange) {\n                return _range;\n            }\n            range = _range.plusRange(_firstRange).plusRange(_lastRange);\n        }\n        let insertPosition = null;\n        for (let i = 0, len = this._pieces.length; i < len; i++) {\n            const piece = this._pieces[i];\n            if (piece.endLineNumber < range.startLineNumber) {\n                // this piece is before the range\n                continue;\n            }\n            if (piece.startLineNumber > range.endLineNumber) {\n                // this piece is after the range, so mark the spot before this piece\n                // as a good insertion position and stop looping\n                insertPosition = insertPosition || { index: i };\n                break;\n            }\n            // this piece might intersect with the range\n            piece.removeTokens(range);\n            if (piece.isEmpty()) {\n                // remove the piece if it became empty\n                this._pieces.splice(i, 1);\n                i--;\n                len--;\n                continue;\n            }\n            if (piece.endLineNumber < range.startLineNumber) {\n                // after removal, this piece is before the range\n                continue;\n            }\n            if (piece.startLineNumber > range.endLineNumber) {\n                // after removal, this piece is after the range\n                insertPosition = insertPosition || { index: i };\n                continue;\n            }\n            // after removal, this piece contains the range\n            const [a, b] = piece.split(range);\n            if (a.isEmpty()) {\n                // this piece is actually after the range\n                insertPosition = insertPosition || { index: i };\n                continue;\n            }\n            if (b.isEmpty()) {\n                // this piece is actually before the range\n                continue;\n            }\n            this._pieces.splice(i, 1, a, b);\n            i++;\n            len++;\n            insertPosition = insertPosition || { index: i };\n        }\n        insertPosition = insertPosition || { index: this._pieces.length };\n        if (pieces.length > 0) {\n            this._pieces = arrays.arrayInsert(this._pieces, insertPosition.index, pieces);\n        }\n        // console.log(`I HAVE ${this._pieces.length} pieces`);\n        // console.log(`${this._pieces.map(p => p.toString()).join('\\n')}`);\n        return range;\n    }\n    isComplete() {\n        return this._isComplete;\n    }\n    addSemanticTokens(lineNumber, aTokens) {\n        const pieces = this._pieces;\n        if (pieces.length === 0) {\n            return aTokens;\n        }\n        const pieceIndex = TokensStore2._findFirstPieceWithLine(pieces, lineNumber);\n        const bTokens = pieces[pieceIndex].getLineTokens(lineNumber);\n        if (!bTokens) {\n            return aTokens;\n        }\n        const aLen = aTokens.getCount();\n        const bLen = bTokens.getCount();\n        let aIndex = 0;\n        let result = [], resultLen = 0;\n        let lastEndOffset = 0;\n        const emitToken = (endOffset, metadata) => {\n            if (endOffset === lastEndOffset) {\n                return;\n            }\n            lastEndOffset = endOffset;\n            result[resultLen++] = endOffset;\n            result[resultLen++] = metadata;\n        };\n        for (let bIndex = 0; bIndex < bLen; bIndex++) {\n            const bStartCharacter = bTokens.getStartCharacter(bIndex);\n            const bEndCharacter = bTokens.getEndCharacter(bIndex);\n            const bMetadata = bTokens.getMetadata(bIndex);\n            const bMask = (((bMetadata & 1 /* SEMANTIC_USE_ITALIC */) ? 2048 /* ITALIC_MASK */ : 0)\n                | ((bMetadata & 2 /* SEMANTIC_USE_BOLD */) ? 4096 /* BOLD_MASK */ : 0)\n                | ((bMetadata & 4 /* SEMANTIC_USE_UNDERLINE */) ? 8192 /* UNDERLINE_MASK */ : 0)\n                | ((bMetadata & 8 /* SEMANTIC_USE_FOREGROUND */) ? 8372224 /* FOREGROUND_MASK */ : 0)\n                | ((bMetadata & 16 /* SEMANTIC_USE_BACKGROUND */) ? 4286578688 /* BACKGROUND_MASK */ : 0)) >>> 0;\n            const aMask = (~bMask) >>> 0;\n            // push any token from `a` that is before `b`\n            while (aIndex < aLen && aTokens.getEndOffset(aIndex) <= bStartCharacter) {\n                emitToken(aTokens.getEndOffset(aIndex), aTokens.getMetadata(aIndex));\n                aIndex++;\n            }\n            // push the token from `a` if it intersects the token from `b`\n            if (aIndex < aLen && aTokens.getStartOffset(aIndex) < bStartCharacter) {\n                emitToken(bStartCharacter, aTokens.getMetadata(aIndex));\n            }\n            // skip any tokens from `a` that are contained inside `b`\n            while (aIndex < aLen && aTokens.getEndOffset(aIndex) < bEndCharacter) {\n                emitToken(aTokens.getEndOffset(aIndex), (aTokens.getMetadata(aIndex) & aMask) | (bMetadata & bMask));\n                aIndex++;\n            }\n            if (aIndex < aLen) {\n                emitToken(bEndCharacter, (aTokens.getMetadata(aIndex) & aMask) | (bMetadata & bMask));\n                if (aTokens.getEndOffset(aIndex) === bEndCharacter) {\n                    // `a` ends exactly at the same spot as `b`!\n                    aIndex++;\n                }\n            }\n            else {\n                const aMergeIndex = Math.min(Math.max(0, aIndex - 1), aLen - 1);\n                // push the token from `b`\n                emitToken(bEndCharacter, (aTokens.getMetadata(aMergeIndex) & aMask) | (bMetadata & bMask));\n            }\n        }\n        // push the remaining tokens from `a`\n        while (aIndex < aLen) {\n            emitToken(aTokens.getEndOffset(aIndex), aTokens.getMetadata(aIndex));\n            aIndex++;\n        }\n        return new LineTokens(new Uint32Array(result), aTokens.getLineContent(), this._languageIdCodec);\n    }\n    static _findFirstPieceWithLine(pieces, lineNumber) {\n        let low = 0;\n        let high = pieces.length - 1;\n        while (low < high) {\n            let mid = low + Math.floor((high - low) / 2);\n            if (pieces[mid].endLineNumber < lineNumber) {\n                low = mid + 1;\n            }\n            else if (pieces[mid].startLineNumber > lineNumber) {\n                high = mid - 1;\n            }\n            else {\n                while (mid > low && pieces[mid - 1].startLineNumber <= lineNumber && lineNumber <= pieces[mid - 1].endLineNumber) {\n                    mid--;\n                }\n                return mid;\n            }\n        }\n        return low;\n    }\n    //#region Editing\n    acceptEdit(range, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n        for (const piece of this._pieces) {\n            piece.acceptEdit(range, eolCount, firstLineLength, lastLineLength, firstCharCode);\n        }\n    }\n}\nexport class TokensStore {\n    constructor(languageIdCodec) {\n        this._lineTokens = [];\n        this._len = 0;\n        this._languageIdCodec = languageIdCodec;\n    }\n    flush() {\n        this._lineTokens = [];\n        this._len = 0;\n    }\n    getTokens(topLevelLanguageId, lineIndex, lineText) {\n        let rawLineTokens = null;\n        if (lineIndex < this._len) {\n            rawLineTokens = this._lineTokens[lineIndex];\n        }\n        if (rawLineTokens !== null && rawLineTokens !== EMPTY_LINE_TOKENS) {\n            return new LineTokens(toUint32Array(rawLineTokens), lineText, this._languageIdCodec);\n        }\n        const lineTokens = new Uint32Array(2);\n        lineTokens[0] = lineText.length;\n        lineTokens[1] = getDefaultMetadata(this._languageIdCodec.encodeLanguageId(topLevelLanguageId));\n        return new LineTokens(lineTokens, lineText, this._languageIdCodec);\n    }\n    static _massageTokens(topLevelLanguageId, lineTextLength, _tokens) {\n        const tokens = _tokens ? toUint32Array(_tokens) : null;\n        if (lineTextLength === 0) {\n            let hasDifferentLanguageId = false;\n            if (tokens && tokens.length > 1) {\n                hasDifferentLanguageId = (TokenMetadata.getLanguageId(tokens[1]) !== topLevelLanguageId);\n            }\n            if (!hasDifferentLanguageId) {\n                return EMPTY_LINE_TOKENS;\n            }\n        }\n        if (!tokens || tokens.length === 0) {\n            const tokens = new Uint32Array(2);\n            tokens[0] = lineTextLength;\n            tokens[1] = getDefaultMetadata(topLevelLanguageId);\n            return tokens.buffer;\n        }\n        // Ensure the last token covers the end of the text\n        tokens[tokens.length - 2] = lineTextLength;\n        if (tokens.byteOffset === 0 && tokens.byteLength === tokens.buffer.byteLength) {\n            // Store directly the ArrayBuffer pointer to save an object\n            return tokens.buffer;\n        }\n        return tokens;\n    }\n    _ensureLine(lineIndex) {\n        while (lineIndex >= this._len) {\n            this._lineTokens[this._len] = null;\n            this._len++;\n        }\n    }\n    _deleteLines(start, deleteCount) {\n        if (deleteCount === 0) {\n            return;\n        }\n        if (start + deleteCount > this._len) {\n            deleteCount = this._len - start;\n        }\n        this._lineTokens.splice(start, deleteCount);\n        this._len -= deleteCount;\n    }\n    _insertLines(insertIndex, insertCount) {\n        if (insertCount === 0) {\n            return;\n        }\n        let lineTokens = [];\n        for (let i = 0; i < insertCount; i++) {\n            lineTokens[i] = null;\n        }\n        this._lineTokens = arrays.arrayInsert(this._lineTokens, insertIndex, lineTokens);\n        this._len += insertCount;\n    }\n    setTokens(topLevelLanguageId, lineIndex, lineTextLength, _tokens, checkEquality) {\n        const tokens = TokensStore._massageTokens(this._languageIdCodec.encodeLanguageId(topLevelLanguageId), lineTextLength, _tokens);\n        this._ensureLine(lineIndex);\n        const oldTokens = this._lineTokens[lineIndex];\n        this._lineTokens[lineIndex] = tokens;\n        if (checkEquality) {\n            return !TokensStore._equals(oldTokens, tokens);\n        }\n        return false;\n    }\n    static _equals(_a, _b) {\n        if (!_a || !_b) {\n            return !_a && !_b;\n        }\n        const a = toUint32Array(_a);\n        const b = toUint32Array(_b);\n        if (a.length !== b.length) {\n            return false;\n        }\n        for (let i = 0, len = a.length; i < len; i++) {\n            if (a[i] !== b[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n    //#region Editing\n    acceptEdit(range, eolCount, firstLineLength) {\n        this._acceptDeleteRange(range);\n        this._acceptInsertText(new Position(range.startLineNumber, range.startColumn), eolCount, firstLineLength);\n    }\n    _acceptDeleteRange(range) {\n        const firstLineIndex = range.startLineNumber - 1;\n        if (firstLineIndex >= this._len) {\n            return;\n        }\n        if (range.startLineNumber === range.endLineNumber) {\n            if (range.startColumn === range.endColumn) {\n                // Nothing to delete\n                return;\n            }\n            this._lineTokens[firstLineIndex] = TokensStore._delete(this._lineTokens[firstLineIndex], range.startColumn - 1, range.endColumn - 1);\n            return;\n        }\n        this._lineTokens[firstLineIndex] = TokensStore._deleteEnding(this._lineTokens[firstLineIndex], range.startColumn - 1);\n        const lastLineIndex = range.endLineNumber - 1;\n        let lastLineTokens = null;\n        if (lastLineIndex < this._len) {\n            lastLineTokens = TokensStore._deleteBeginning(this._lineTokens[lastLineIndex], range.endColumn - 1);\n        }\n        // Take remaining text on last line and append it to remaining text on first line\n        this._lineTokens[firstLineIndex] = TokensStore._append(this._lineTokens[firstLineIndex], lastLineTokens);\n        // Delete middle lines\n        this._deleteLines(range.startLineNumber, range.endLineNumber - range.startLineNumber);\n    }\n    _acceptInsertText(position, eolCount, firstLineLength) {\n        if (eolCount === 0 && firstLineLength === 0) {\n            // Nothing to insert\n            return;\n        }\n        const lineIndex = position.lineNumber - 1;\n        if (lineIndex >= this._len) {\n            return;\n        }\n        if (eolCount === 0) {\n            // Inserting text on one line\n            this._lineTokens[lineIndex] = TokensStore._insert(this._lineTokens[lineIndex], position.column - 1, firstLineLength);\n            return;\n        }\n        this._lineTokens[lineIndex] = TokensStore._deleteEnding(this._lineTokens[lineIndex], position.column - 1);\n        this._lineTokens[lineIndex] = TokensStore._insert(this._lineTokens[lineIndex], position.column - 1, firstLineLength);\n        this._insertLines(position.lineNumber, eolCount);\n    }\n    static _deleteBeginning(lineTokens, toChIndex) {\n        if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS) {\n            return lineTokens;\n        }\n        return TokensStore._delete(lineTokens, 0, toChIndex);\n    }\n    static _deleteEnding(lineTokens, fromChIndex) {\n        if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS) {\n            return lineTokens;\n        }\n        const tokens = toUint32Array(lineTokens);\n        const lineTextLength = tokens[tokens.length - 2];\n        return TokensStore._delete(lineTokens, fromChIndex, lineTextLength);\n    }\n    static _delete(lineTokens, fromChIndex, toChIndex) {\n        if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS || fromChIndex === toChIndex) {\n            return lineTokens;\n        }\n        const tokens = toUint32Array(lineTokens);\n        const tokensCount = (tokens.length >>> 1);\n        // special case: deleting everything\n        if (fromChIndex === 0 && tokens[tokens.length - 2] === toChIndex) {\n            return EMPTY_LINE_TOKENS;\n        }\n        const fromTokenIndex = LineTokens.findIndexInTokensArray(tokens, fromChIndex);\n        const fromTokenStartOffset = (fromTokenIndex > 0 ? tokens[(fromTokenIndex - 1) << 1] : 0);\n        const fromTokenEndOffset = tokens[fromTokenIndex << 1];\n        if (toChIndex < fromTokenEndOffset) {\n            // the delete range is inside a single token\n            const delta = (toChIndex - fromChIndex);\n            for (let i = fromTokenIndex; i < tokensCount; i++) {\n                tokens[i << 1] -= delta;\n            }\n            return lineTokens;\n        }\n        let dest;\n        let lastEnd;\n        if (fromTokenStartOffset !== fromChIndex) {\n            tokens[fromTokenIndex << 1] = fromChIndex;\n            dest = ((fromTokenIndex + 1) << 1);\n            lastEnd = fromChIndex;\n        }\n        else {\n            dest = (fromTokenIndex << 1);\n            lastEnd = fromTokenStartOffset;\n        }\n        const delta = (toChIndex - fromChIndex);\n        for (let tokenIndex = fromTokenIndex + 1; tokenIndex < tokensCount; tokenIndex++) {\n            const tokenEndOffset = tokens[tokenIndex << 1] - delta;\n            if (tokenEndOffset > lastEnd) {\n                tokens[dest++] = tokenEndOffset;\n                tokens[dest++] = tokens[(tokenIndex << 1) + 1];\n                lastEnd = tokenEndOffset;\n            }\n        }\n        if (dest === tokens.length) {\n            // nothing to trim\n            return lineTokens;\n        }\n        let tmp = new Uint32Array(dest);\n        tmp.set(tokens.subarray(0, dest), 0);\n        return tmp.buffer;\n    }\n    static _append(lineTokens, _otherTokens) {\n        if (_otherTokens === EMPTY_LINE_TOKENS) {\n            return lineTokens;\n        }\n        if (lineTokens === EMPTY_LINE_TOKENS) {\n            return _otherTokens;\n        }\n        if (lineTokens === null) {\n            return lineTokens;\n        }\n        if (_otherTokens === null) {\n            // cannot determine combined line length...\n            return null;\n        }\n        const myTokens = toUint32Array(lineTokens);\n        const otherTokens = toUint32Array(_otherTokens);\n        const otherTokensCount = (otherTokens.length >>> 1);\n        let result = new Uint32Array(myTokens.length + otherTokens.length);\n        result.set(myTokens, 0);\n        let dest = myTokens.length;\n        const delta = myTokens[myTokens.length - 2];\n        for (let i = 0; i < otherTokensCount; i++) {\n            result[dest++] = otherTokens[(i << 1)] + delta;\n            result[dest++] = otherTokens[(i << 1) + 1];\n        }\n        return result.buffer;\n    }\n    static _insert(lineTokens, chIndex, textLength) {\n        if (lineTokens === null || lineTokens === EMPTY_LINE_TOKENS) {\n            // nothing to do\n            return lineTokens;\n        }\n        const tokens = toUint32Array(lineTokens);\n        const tokensCount = (tokens.length >>> 1);\n        let fromTokenIndex = LineTokens.findIndexInTokensArray(tokens, chIndex);\n        if (fromTokenIndex > 0) {\n            const fromTokenStartOffset = tokens[(fromTokenIndex - 1) << 1];\n            if (fromTokenStartOffset === chIndex) {\n                fromTokenIndex--;\n            }\n        }\n        for (let tokenIndex = fromTokenIndex; tokenIndex < tokensCount; tokenIndex++) {\n            tokens[tokenIndex << 1] += textLength;\n        }\n        return lineTokens;\n    }\n}\n"]},"metadata":{},"sourceType":"module"}